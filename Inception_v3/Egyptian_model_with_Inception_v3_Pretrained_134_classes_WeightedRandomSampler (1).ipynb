{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Egyptian_model_with_Inception_v3_Pretrained_134_classes_WeightedRandomSampler.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "18a00db0144846d1b25cc346f86d6508": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f5e115869e9e498ca1e97294a7a26ec0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_76f5b576fda046d08d382d9947817ec1",
              "IPY_MODEL_53195db84eda4189a9a366508639f0e5",
              "IPY_MODEL_d8b6847637904338a2ba6155ef9547b4"
            ]
          }
        },
        "f5e115869e9e498ca1e97294a7a26ec0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "76f5b576fda046d08d382d9947817ec1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_362edaa1f85e4aa38ed4d4ba1a4956c2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_effda75433ea4bcf8ee9504681614ea3"
          }
        },
        "53195db84eda4189a9a366508639f0e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_258257c52898488a97cc6a87f5992840",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 108949747,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 108949747,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7800ef868084431b94c31f87da101f8c"
          }
        },
        "d8b6847637904338a2ba6155ef9547b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9d3fcf4cc04b4b3a9e9219c5e2bb0f11",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 104M/104M [00:01&lt;00:00, 76.5MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e5be6db9acf6406e8b5a674e2c5a2176"
          }
        },
        "362edaa1f85e4aa38ed4d4ba1a4956c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "effda75433ea4bcf8ee9504681614ea3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "258257c52898488a97cc6a87f5992840": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7800ef868084431b94c31f87da101f8c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9d3fcf4cc04b4b3a9e9219c5e2bb0f11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e5be6db9acf6406e8b5a674e2c5a2176": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8iEiGSblxJzW"
      },
      "source": [
        "import os, os.path\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from pathlib import Path\n",
        "from torchvision import datasets, models, transforms\n",
        "\n",
        "# check if CUDA is available\n",
        "train_on_gpu = torch.cuda.is_available()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jd6KU8VMz6J3"
      },
      "source": [
        "Module: Load_data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enB3iLoNDHFm"
      },
      "source": [
        "def get_class_distribution(dataset_obj, idx2class):\n",
        "    count_dict = {k:0 for k,v in dataset_obj.class_to_idx.items()}\n",
        "    \n",
        "    for element in dataset_obj:\n",
        "        y_lbl = element[1]\n",
        "        y_lbl = idx2class[y_lbl]\n",
        "        count_dict[y_lbl] += 1\n",
        "            \n",
        "    return count_dict"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lWX0BW_w_kC"
      },
      "source": [
        "def load_data(hieroglyph_directory_path, batch_size=20, num_workers=0):\n",
        "    train_dir = os.path.join(hieroglyph_directory_path, 'train/')\n",
        "    test_dir = os.path.join(hieroglyph_directory_path, 'test/')\n",
        "\n",
        "    classes = []\n",
        "\n",
        "    for filename in os.listdir(train_dir):\n",
        "        if filename == '.DS_Store':\n",
        "            pass\n",
        "        else:\n",
        "            classes.append(filename)\n",
        "\n",
        "    classes.sort()\n",
        "\n",
        "    # print(\"Our classes:\", classes)\n",
        "    # print(len(classes))\n",
        "\n",
        "    data_transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                            transforms.RandomApply([transforms.RandomHorizontalFlip()]),\n",
        "                                            transforms.RandomRotation(degrees=(-10, 10)),\n",
        "                                            transforms.RandomAffine(degrees=0, translate=(.1, .1)),\n",
        "                                            transforms.RandomApply([transforms.ColorJitter(brightness=(1, 1.2),\n",
        "                                                                                            contrast=(1, 1.5),\n",
        "                                                                                            saturation=(1, 1.5),\n",
        "                                                                                            hue=(0, 0.5))]),\n",
        "                                            transforms.RandomErasing(p=0.5, scale=(0.05, 0.05), ratio=(0.3, 3.3), value=0,\n",
        "                                                                      inplace=False),\n",
        "                                            transforms.Resize((299, 299)),\n",
        "                                            transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "    train_data = datasets.ImageFolder(train_dir, transform=data_transform)\n",
        "    test_data = datasets.ImageFolder(test_dir, transform=data_transform)\n",
        "\n",
        "\n",
        "    # print('Num training images: ', len(train_data))\n",
        "    # print('Num test images: ', len(test_data))\n",
        "\n",
        "\n",
        "    # WeightedRandomSampler\n",
        "    idx2class = {v: k for k, v in train_data.class_to_idx.items()}\n",
        "\n",
        "    target_list = torch.tensor(train_data.targets)\n",
        "    class_count = [i for i in get_class_distribution(train_data, idx2class).values()]\n",
        "    class_weights = 1./torch.tensor(class_count, dtype=torch.float) \n",
        "    class_weights_all = class_weights[target_list]\n",
        "    weighted_sampler = torch.utils.data.WeightedRandomSampler(weights=class_weights_all, num_samples=len(class_weights_all), replacement=True)\n",
        "\n",
        "\n",
        "    # prepare data loaders\n",
        "    train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
        "                                               num_workers=num_workers, sampler=weighted_sampler, drop_last=True)\n",
        "    test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size,\n",
        "                                              num_workers=num_workers, shuffle=True)\n",
        "\n",
        "    return train_loader, test_loader, classes"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4sXUrPPz7iF"
      },
      "source": [
        "Module: Train_model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2N_rnKLxN5c"
      },
      "source": [
        "def train_model(train_loader, optimizer, conv_net_model, criterion, my_lr_scheduler, n_epochs):\n",
        "    # track training loss over time\n",
        "    losses = []\n",
        "    \n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "\n",
        "        # keep track of training and validation loss\n",
        "        train_loss = 0.0\n",
        "\n",
        "        # model by default is set to train\n",
        "        for batch_i, (data, target) in enumerate(train_loader):\n",
        "            # move tensors to GPU if CUDA is available\n",
        "            if train_on_gpu:\n",
        "                data, target = data.cuda(), target.cuda()\n",
        "            # clear the gradients of all optimized variables\n",
        "            optimizer.zero_grad()\n",
        "            # forward pass: compute predicted outputs by passing inputs to the model\n",
        "            output = conv_net_model(data)\n",
        "            # calculate the batch loss\n",
        "            loss = criterion(output.logits, target)\n",
        "            # backward pass: compute gradient of the loss with respect to model parameters\n",
        "            loss.backward()\n",
        "            # perform a single optimization step (parameter update)\n",
        "            optimizer.step()\n",
        "            # update training loss\n",
        "            train_loss += loss.item()\n",
        "\n",
        "            my_lr_scheduler.step()\n",
        "\n",
        "            if batch_i % 20 == 19:  # print training loss every specified number of mini-batches\n",
        "                print('Epoch %d, Batch %d loss: %.16f' %\n",
        "                    (epoch, batch_i + 1, train_loss / 20))\n",
        "                losses.append(train_loss / 20)\n",
        "                train_loss = 0.0\n",
        "\n",
        "    return conv_net_model, losses"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Rrxo5RDz96U"
      },
      "source": [
        "Module: Test_model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ay-HlMJnxU9v"
      },
      "source": [
        "def test_model(classes, conv_net_model, test_loader, criterion):\n",
        "    # track test loss\n",
        "    test_loss = 0.0\n",
        "    class_correct = list(0. for i in range(len(classes)))\n",
        "    class_total = list(0. for i in range(len(classes)))\n",
        "\n",
        "    conv_net_model.eval()  # eval mode\n",
        "\n",
        "    labels = []\n",
        "    predictions = []\n",
        "    # iterate over test data\n",
        "    for data, target in test_loader:\n",
        "        # move tensors to GPU if CUDA is available\n",
        "        if train_on_gpu:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        # forward pass: compute predicted outputs by passing inputs to the model\n",
        "        output = conv_net_model(data)\n",
        "        # calculate the batch loss\n",
        "        loss = criterion(output, target)\n",
        "        # update  test loss\n",
        "        test_loss += loss.item() * data.size(0)\n",
        "        # convert output probabilities to predicted class\n",
        "        _, pred = torch.max(output, 1)\n",
        "        # compare predictions to true label\n",
        "        correct_tensor = pred.eq(target.data.view_as(pred))\n",
        "        correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
        "        # calculate test accuracy for each object class\n",
        "        for i in range(len(target.data)):\n",
        "            label = target.data[i]\n",
        "            class_correct[label] += correct[i].item()\n",
        "            class_total[label] += 1\n",
        "        \n",
        "        # Will be used for calculating Recall, Precision, and F1-score\n",
        "        labels.extend(target.data.view_as(pred).tolist())\n",
        "        predictions.extend(pred.tolist())\n",
        "\n",
        "\n",
        "    # calculate avg test loss\n",
        "    test_loss = test_loss / len(test_loader.dataset)\n",
        "    print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
        "\n",
        "    return test_loss, class_correct, class_total, labels, predictions"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHh3PXE80Asa"
      },
      "source": [
        "Check whether CUDA is available (Change runtime type if not)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9TYPQH7x4zw",
        "outputId": "b7f33e42-97cf-40b4-8c36-c87312d15efd"
      },
      "source": [
        "if not train_on_gpu:\n",
        "    print('CUDA is not available.  Training on CPU ...')\n",
        "else:\n",
        "    print('CUDA is available!  Training on GPU ...')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA is available!  Training on GPU ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lYw8EKVx8Q7"
      },
      "source": [
        "Load Hieroglyph Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "laLvoRy1yewl",
        "outputId": "14f4a807-d3b2-4841-a1e6-e1194afecc90"
      },
      "source": [
        "# Connecting and Mounting to the Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odaoZt9GyfUt"
      },
      "source": [
        "data_dir = '/content/drive/MyDrive/EgyptianHieroglyphDataset_134/'"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dF22MAnmyiC1",
        "outputId": "2720b25b-b44f-4736-ffa1-82cad7c0349e"
      },
      "source": [
        "hieroglyph_for_train = []\n",
        "file_count_list = []\n",
        "\n",
        "for name in os.listdir('/content/drive/MyDrive/EgyptianHieroglyphDataset_134/train/'):\n",
        "  path, dirs, files = next(os.walk(\"/content/drive/MyDrive/EgyptianHieroglyphDataset_134/train/\"+name))\n",
        "  file_count = len(files)\n",
        "  if file_count == 0:\n",
        "    continue\n",
        "  else:\n",
        "    print(name, file_count)\n",
        "    file_count_list.append(file_count)\n",
        "    hieroglyph_for_train.append(name)\n",
        "\n",
        "hieroglyph_dict = dict(zip(hieroglyph_for_train, file_count_list))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aa15 2\n",
            "Aa26 4\n",
            "Aa27 2\n",
            "Z1 39\n",
            "Z11 8\n",
            "Z7 3\n",
            "Y2 5\n",
            "Y3 2\n",
            "Y5 6\n",
            "E34 97\n",
            "E1 5\n",
            "E23 8\n",
            "E9 8\n",
            "W18 5\n",
            "W24 31\n",
            "W11 4\n",
            "W22 1\n",
            "W19 3\n",
            "W25 9\n",
            "D21 146\n",
            "D4 29\n",
            "D46 40\n",
            "D1 4\n",
            "D36 47\n",
            "D58 28\n",
            "D2 19\n",
            "D35 45\n",
            "D60 4\n",
            "D28 13\n",
            "D10 2\n",
            "D39 1\n",
            "D56 2\n",
            "D19 2\n",
            "D52 4\n",
            "D54 9\n",
            "D156 2\n",
            "X1 185\n",
            "X8 4\n",
            "U15 10\n",
            "U28 2\n",
            "U1 20\n",
            "U33 13\n",
            "U7 3\n",
            "T28 1\n",
            "T22 7\n",
            "T21 2\n",
            "T20 3\n",
            "T30 2\n",
            "V31 106\n",
            "V28 28\n",
            "V13 63\n",
            "V4 10\n",
            "V30 6\n",
            "V7 4\n",
            "V24 4\n",
            "V6 1\n",
            "R8 53\n",
            "R4 2\n",
            "Q3 61\n",
            "Q1 13\n",
            "Q7 2\n",
            "P8 12\n",
            "P6 2\n",
            "P98 4\n",
            "P1 4\n",
            "S29 212\n",
            "S34 8\n",
            "S24 1\n",
            "S28 1\n",
            "O50 84\n",
            "O49 10\n",
            "O28 8\n",
            "O34 15\n",
            "O1 16\n",
            "O31 5\n",
            "O4 11\n",
            "I9 116\n",
            "I10 32\n",
            "G17 156\n",
            "L1 2\n",
            "M17 291\n",
            "M44 5\n",
            "M42 4\n",
            "M1 2\n",
            "M12 2\n",
            "M18 10\n",
            "M195 2\n",
            "M20 2\n",
            "M23 30\n",
            "M41 2\n",
            "M3 3\n",
            "M16 1\n",
            "M8 1\n",
            "M40 2\n",
            "M29 2\n",
            "H6 5\n",
            "N35 358\n",
            "N5 16\n",
            "N1 14\n",
            "N37 24\n",
            "N14 11\n",
            "N31 13\n",
            "N17 6\n",
            "N29 14\n",
            "N18 15\n",
            "N41 2\n",
            "N30 9\n",
            "N25 1\n",
            "N36 1\n",
            "F13 6\n",
            "F16 5\n",
            "F35 2\n",
            "F34 8\n",
            "F31 6\n",
            "F4 3\n",
            "F40 1\n",
            "F18 4\n",
            "F9 2\n",
            "F26 3\n",
            "G39 16\n",
            "G43 157\n",
            "G5 24\n",
            "G40 6\n",
            "G7 8\n",
            "G35 30\n",
            "G1 28\n",
            "G21 1\n",
            "G25 21\n",
            "G36 7\n",
            "G4 6\n",
            "G14 1\n",
            "G26 1\n",
            "G29 2\n",
            "G37 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XeQQ7PjZzKd9"
      },
      "source": [
        "Number of images for each hieroglyph "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        },
        "id": "W6IzWR2RyjxM",
        "outputId": "aad7be5f-5e07-4743-f573-aff1b34ac54d"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame({\"Hieroglyph\":hieroglyph_for_train, \"Count\":file_count_list})\n",
        "\n",
        "df_sorted= df.sort_values('Count',ascending=False)\n",
        "\n",
        "plt.figure(figsize=(100,10))\n",
        "# make bar plot with matplotlib\n",
        "plt.bar('Hieroglyph', 'Count',data=df_sorted)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 134 artists>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 7200x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xj7nMcJg2fsH",
        "outputId": "4d83a352-a03c-4aae-cb5f-307603d6b083"
      },
      "source": [
        "print(len(hieroglyph_for_train))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "134\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGXpsABT4sac",
        "outputId": "b57be0ba-868f-4a75-e4ae-ee0db05bf0b9"
      },
      "source": [
        "print(hieroglyph_for_train)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Aa15', 'Aa26', 'Aa27', 'Z1', 'Z11', 'Z7', 'Y2', 'Y3', 'Y5', 'E34', 'E1', 'E23', 'E9', 'W18', 'W24', 'W11', 'W22', 'W19', 'W25', 'D21', 'D4', 'D46', 'D1', 'D36', 'D58', 'D2', 'D35', 'D60', 'D28', 'D10', 'D39', 'D56', 'D19', 'D52', 'D54', 'D156', 'X1', 'X8', 'U15', 'U28', 'U1', 'U33', 'U7', 'T28', 'T22', 'T21', 'T20', 'T30', 'V31', 'V28', 'V13', 'V4', 'V30', 'V7', 'V24', 'V6', 'R8', 'R4', 'Q3', 'Q1', 'Q7', 'P8', 'P6', 'P98', 'P1', 'S29', 'S34', 'S24', 'S28', 'O50', 'O49', 'O28', 'O34', 'O1', 'O31', 'O4', 'I9', 'I10', 'G17', 'L1', 'M17', 'M44', 'M42', 'M1', 'M12', 'M18', 'M195', 'M20', 'M23', 'M41', 'M3', 'M16', 'M8', 'M40', 'M29', 'H6', 'N35', 'N5', 'N1', 'N37', 'N14', 'N31', 'N17', 'N29', 'N18', 'N41', 'N30', 'N25', 'N36', 'F13', 'F16', 'F35', 'F34', 'F31', 'F4', 'F40', 'F18', 'F9', 'F26', 'G39', 'G43', 'G5', 'G40', 'G7', 'G35', 'G1', 'G21', 'G25', 'G36', 'G4', 'G14', 'G26', 'G29', 'G37']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3oOm8rSx7tp"
      },
      "source": [
        "# Number of images processed in a single training\n",
        "batch_size = 20\n",
        "num_workers = 0\n",
        "\n",
        "# The load_data function is from hieroglyph_data_preparation python file\n",
        "train_loader, test_loader, classes = load_data(data_dir)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJm8sGiBx_q5"
      },
      "source": [
        "Inception-v3 Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhoPdBITy6kP"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, gamma=0, alpha=None, size_average=True):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.gamma = gamma\n",
        "        self.alpha = alpha\n",
        "        if isinstance(alpha,(float,int)): self.alpha = torch.Tensor([alpha,1-alpha])\n",
        "        if isinstance(alpha,list): self.alpha = torch.Tensor(alpha)\n",
        "        self.size_average = size_average\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        if input.dim()>2:\n",
        "            input = input.view(input.size(0),input.size(1),-1)  # N,C,H,W => N,C,H*W\n",
        "            input = input.transpose(1,2)    # N,C,H*W => N,H*W,C\n",
        "            input = input.contiguous().view(-1,input.size(2))   # N,H*W,C => N*H*W,C\n",
        "        target = target.view(-1,1)\n",
        "\n",
        "        logpt = torch.nn.functional.log_softmax(input, -1)\n",
        "        logpt = logpt.gather(1,target)\n",
        "        logpt = logpt.view(-1)\n",
        "        pt = Variable(logpt.data.exp())\n",
        "\n",
        "        if self.alpha is not None:\n",
        "            if self.alpha.type()!=input.data.type():\n",
        "                self.alpha = self.alpha.type_as(input.data)\n",
        "            at = self.alpha.gather(0,target.data.view(-1))\n",
        "            logpt = logpt * Variable(at)\n",
        "\n",
        "        loss = -1 * (1-pt)**self.gamma * logpt\n",
        "        if self.size_average: return loss.mean()\n",
        "        else: return loss.sum()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkLXVJGkxemC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "18a00db0144846d1b25cc346f86d6508",
            "f5e115869e9e498ca1e97294a7a26ec0",
            "76f5b576fda046d08d382d9947817ec1",
            "53195db84eda4189a9a366508639f0e5",
            "d8b6847637904338a2ba6155ef9547b4",
            "362edaa1f85e4aa38ed4d4ba1a4956c2",
            "effda75433ea4bcf8ee9504681614ea3",
            "258257c52898488a97cc6a87f5992840",
            "7800ef868084431b94c31f87da101f8c",
            "9d3fcf4cc04b4b3a9e9219c5e2bb0f11",
            "e5be6db9acf6406e8b5a674e2c5a2176"
          ]
        },
        "outputId": "ae1fafbe-4ced-4e9b-c3cc-1f16520c27be"
      },
      "source": [
        "# Whether to extract features with the model\n",
        "feature_extract = False\n",
        "# Other selections\n",
        "loss_function = \"cross-entropy\"\n",
        "model_selection = \"inception-v3\"\n",
        "optim_selection = \"Adam\"\n",
        "\n",
        "# False if you want scratch model, True if you want pretrained model\n",
        "whether_to_pretrain = True\n",
        "\n",
        "# Load the model\n",
        "if model_selection == \"resnet-50\":\n",
        "    resnet50 = models.resnet50(pretrained=whether_to_pretrain)\n",
        "    # Number of features in the last layer of resnet\n",
        "    n_inputs = resnet50.fc.in_features\n",
        "    # Add last linear layer (n_inputs -> 40 hieroglyph classes)\n",
        "    last_layer = nn.Sequential(\n",
        "                    nn.Linear(n_inputs, len(classes)))\n",
        "    resnet50.fc = last_layer\n",
        "    if train_on_gpu:\n",
        "      resnet50.cuda()\n",
        "    # Specify optimizer (Adam) and learning rate = 0.001\n",
        "    if optim_selection == \"Adam\":\n",
        "        optimizer = optim.Adam(resnet50.parameters(), lr=0.001)\n",
        "\n",
        "elif model_selection == \"inception-v3\":\n",
        "    inception_v3 = models.inception_v3(pretrained=whether_to_pretrain)\n",
        "    # Number of features in the last layer of resnet\n",
        "    n_inputs = inception_v3.fc.in_features\n",
        "    # Add last linear layer (n_inputs -> 40 hieroglyph classes)\n",
        "    last_layer = nn.Sequential(\n",
        "                    nn.Linear(n_inputs, len(classes)))\n",
        "    inception_v3.fc = last_layer\n",
        "    if train_on_gpu:\n",
        "      inception_v3.cuda()\n",
        "    # Specify optimizer (Adam) and learning rate = 0.001\n",
        "    if optim_selection == \"Adam\":\n",
        "        optimizer = optim.Adam(inception_v3.parameters(), lr=0.001)\n",
        "\n",
        "\n",
        "# Specify loss function (categorical cross-entropy)\n",
        "if loss_function == \"cross-entropy\":\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "elif loss_function == \"focal-loss\":\n",
        "    criterion = FocalLoss(gamma=0)\n",
        "\n",
        "# Exponential Decay to strengthen learning\n",
        "decayRate = 0.999\n",
        "my_lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=decayRate)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/inception_v3_google-0cc3c7bd.pth\" to /root/.cache/torch/hub/checkpoints/inception_v3_google-0cc3c7bd.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "18a00db0144846d1b25cc346f86d6508",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0.00/104M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2vnErB1yHmM"
      },
      "source": [
        "Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOB03noWyEvQ",
        "outputId": "f8da275c-7d0b-4e5a-9c4b-dff0daabe8bc"
      },
      "source": [
        "# number of epochs to train the model\n",
        "n_epochs = 100\n",
        "\n",
        "if model_selection == \"resnet-50\":\n",
        "  # The train_model function is from model_training python file\n",
        "  resnet50, train_losses = train_model(train_loader, optimizer, resnet50, criterion, my_lr_scheduler, n_epochs)\n",
        "elif model_selection == \"inception-v3\":\n",
        "  # The train_model function is from model_training python file\n",
        "  inception_v3, train_losses = train_model(train_loader, optimizer, inception_v3, criterion, my_lr_scheduler, n_epochs)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Batch 20 loss: 5.0682315826416016\n",
            "Epoch 1, Batch 40 loss: 4.9426983118057253\n",
            "Epoch 1, Batch 60 loss: 4.9078647375106810\n",
            "Epoch 1, Batch 80 loss: 4.8966625690460202\n",
            "Epoch 1, Batch 100 loss: 4.8030730009078981\n",
            "Epoch 1, Batch 120 loss: 4.7827763557434082\n",
            "Epoch 1, Batch 140 loss: 4.7277869224548343\n",
            "Epoch 2, Batch 20 loss: 4.5768846750259398\n",
            "Epoch 2, Batch 40 loss: 4.4372443675994875\n",
            "Epoch 2, Batch 60 loss: 4.4044868946075439\n",
            "Epoch 2, Batch 80 loss: 4.2708026051521299\n",
            "Epoch 2, Batch 100 loss: 4.0458405256271366\n",
            "Epoch 2, Batch 120 loss: 4.0257914662361145\n",
            "Epoch 2, Batch 140 loss: 3.8828584909439088\n",
            "Epoch 3, Batch 20 loss: 3.6581494927406313\n",
            "Epoch 3, Batch 40 loss: 3.6481094241142271\n",
            "Epoch 3, Batch 60 loss: 3.4170700430870058\n",
            "Epoch 3, Batch 80 loss: 3.2202834248542787\n",
            "Epoch 3, Batch 100 loss: 3.1310631394386292\n",
            "Epoch 3, Batch 120 loss: 2.9528781414031982\n",
            "Epoch 3, Batch 140 loss: 2.7781792759895323\n",
            "Epoch 4, Batch 20 loss: 2.7065545439720156\n",
            "Epoch 4, Batch 40 loss: 2.5767650723457338\n",
            "Epoch 4, Batch 60 loss: 2.3494723558425905\n",
            "Epoch 4, Batch 80 loss: 2.1417811870574952\n",
            "Epoch 4, Batch 100 loss: 2.1590188384056090\n",
            "Epoch 4, Batch 120 loss: 2.1811723828315737\n",
            "Epoch 4, Batch 140 loss: 1.9634864807128907\n",
            "Epoch 5, Batch 20 loss: 1.7791727960109711\n",
            "Epoch 5, Batch 40 loss: 1.6228609621524810\n",
            "Epoch 5, Batch 60 loss: 1.6168610751628876\n",
            "Epoch 5, Batch 80 loss: 1.4803596973419189\n",
            "Epoch 5, Batch 100 loss: 1.4852210044860841\n",
            "Epoch 5, Batch 120 loss: 1.4141626596450805\n",
            "Epoch 5, Batch 140 loss: 1.2061127871274948\n",
            "Epoch 6, Batch 20 loss: 1.2179432392120362\n",
            "Epoch 6, Batch 40 loss: 1.2304594755172729\n",
            "Epoch 6, Batch 60 loss: 1.0555877059698104\n",
            "Epoch 6, Batch 80 loss: 0.9553679972887039\n",
            "Epoch 6, Batch 100 loss: 0.8857645153999328\n",
            "Epoch 6, Batch 120 loss: 0.9191788524389267\n",
            "Epoch 6, Batch 140 loss: 0.7917187526822090\n",
            "Epoch 7, Batch 20 loss: 0.7315077066421509\n",
            "Epoch 7, Batch 40 loss: 0.7996680259704589\n",
            "Epoch 7, Batch 60 loss: 0.7961465612053871\n",
            "Epoch 7, Batch 80 loss: 0.6300271466374397\n",
            "Epoch 7, Batch 100 loss: 0.6377475082874298\n",
            "Epoch 7, Batch 120 loss: 0.5578948572278023\n",
            "Epoch 7, Batch 140 loss: 0.5813841059803962\n",
            "Epoch 8, Batch 20 loss: 0.5419007360935211\n",
            "Epoch 8, Batch 40 loss: 0.5953185901045799\n",
            "Epoch 8, Batch 60 loss: 0.5341145306825638\n",
            "Epoch 8, Batch 80 loss: 0.5399943351745605\n",
            "Epoch 8, Batch 100 loss: 0.4678175866603851\n",
            "Epoch 8, Batch 120 loss: 0.4825173363089562\n",
            "Epoch 8, Batch 140 loss: 0.3928587846457958\n",
            "Epoch 9, Batch 20 loss: 0.4321805052459240\n",
            "Epoch 9, Batch 40 loss: 0.4158434852957725\n",
            "Epoch 9, Batch 60 loss: 0.2986479625105858\n",
            "Epoch 9, Batch 80 loss: 0.4013333462178707\n",
            "Epoch 9, Batch 100 loss: 0.3322766456753016\n",
            "Epoch 9, Batch 120 loss: 0.4226253740489483\n",
            "Epoch 9, Batch 140 loss: 0.3329187877476215\n",
            "Epoch 10, Batch 20 loss: 0.3063533890992403\n",
            "Epoch 10, Batch 40 loss: 0.2533667750656605\n",
            "Epoch 10, Batch 60 loss: 0.3203572157770395\n",
            "Epoch 10, Batch 80 loss: 0.2931191869080066\n",
            "Epoch 10, Batch 100 loss: 0.2705859731882810\n",
            "Epoch 10, Batch 120 loss: 0.3587352946400643\n",
            "Epoch 10, Batch 140 loss: 0.3143348600715399\n",
            "Epoch 11, Batch 20 loss: 0.2458329858258367\n",
            "Epoch 11, Batch 40 loss: 0.2004336291924119\n",
            "Epoch 11, Batch 60 loss: 0.3143778374418617\n",
            "Epoch 11, Batch 80 loss: 0.3044599756598473\n",
            "Epoch 11, Batch 100 loss: 0.2311305895447731\n",
            "Epoch 11, Batch 120 loss: 0.2072136212140322\n",
            "Epoch 11, Batch 140 loss: 0.2622724596410990\n",
            "Epoch 12, Batch 20 loss: 0.2274130269885063\n",
            "Epoch 12, Batch 40 loss: 0.1969230901449919\n",
            "Epoch 12, Batch 60 loss: 0.2138011418282986\n",
            "Epoch 12, Batch 80 loss: 0.1681536107324064\n",
            "Epoch 12, Batch 100 loss: 0.2048096859827638\n",
            "Epoch 12, Batch 120 loss: 0.1582101278007030\n",
            "Epoch 12, Batch 140 loss: 0.1683564066886902\n",
            "Epoch 13, Batch 20 loss: 0.1596871631219983\n",
            "Epoch 13, Batch 40 loss: 0.1566257148981094\n",
            "Epoch 13, Batch 60 loss: 0.1798499148339033\n",
            "Epoch 13, Batch 80 loss: 0.1781414598226547\n",
            "Epoch 13, Batch 100 loss: 0.1569481244310737\n",
            "Epoch 13, Batch 120 loss: 0.1187663365155458\n",
            "Epoch 13, Batch 140 loss: 0.1461572840344161\n",
            "Epoch 14, Batch 20 loss: 0.1299375360365957\n",
            "Epoch 14, Batch 40 loss: 0.1573571889661252\n",
            "Epoch 14, Batch 60 loss: 0.1319503671489656\n",
            "Epoch 14, Batch 80 loss: 0.1425863049924374\n",
            "Epoch 14, Batch 100 loss: 0.1398266499862075\n",
            "Epoch 14, Batch 120 loss: 0.1356817377731204\n",
            "Epoch 14, Batch 140 loss: 0.1188890941441059\n",
            "Epoch 15, Batch 20 loss: 0.1162889891304076\n",
            "Epoch 15, Batch 40 loss: 0.1201038485392928\n",
            "Epoch 15, Batch 60 loss: 0.1368522990029305\n",
            "Epoch 15, Batch 80 loss: 0.1443141918629408\n",
            "Epoch 15, Batch 100 loss: 0.1277357087470591\n",
            "Epoch 15, Batch 120 loss: 0.0900701022706926\n",
            "Epoch 15, Batch 140 loss: 0.1149252520874143\n",
            "Epoch 16, Batch 20 loss: 0.0936006370000541\n",
            "Epoch 16, Batch 40 loss: 0.1002034662291408\n",
            "Epoch 16, Batch 60 loss: 0.1154418405145407\n",
            "Epoch 16, Batch 80 loss: 0.0875146530102938\n",
            "Epoch 16, Batch 100 loss: 0.1144940955564380\n",
            "Epoch 16, Batch 120 loss: 0.0980717225000262\n",
            "Epoch 16, Batch 140 loss: 0.0662331417202950\n",
            "Epoch 17, Batch 20 loss: 0.0980537701398134\n",
            "Epoch 17, Batch 40 loss: 0.0838823826052248\n",
            "Epoch 17, Batch 60 loss: 0.0909979703836143\n",
            "Epoch 17, Batch 80 loss: 0.0751972481142729\n",
            "Epoch 17, Batch 100 loss: 0.0827020686585456\n",
            "Epoch 17, Batch 120 loss: 0.1385044027119875\n",
            "Epoch 17, Batch 140 loss: 0.1113778171129525\n",
            "Epoch 18, Batch 20 loss: 0.0682454191381112\n",
            "Epoch 18, Batch 40 loss: 0.0532446715980768\n",
            "Epoch 18, Batch 60 loss: 0.0726449601352215\n",
            "Epoch 18, Batch 80 loss: 0.0616679099388421\n",
            "Epoch 18, Batch 100 loss: 0.0764125421177596\n",
            "Epoch 18, Batch 120 loss: 0.0758757527917624\n",
            "Epoch 18, Batch 140 loss: 0.0747461316641420\n",
            "Epoch 19, Batch 20 loss: 0.0956630668602884\n",
            "Epoch 19, Batch 40 loss: 0.0596586511470377\n",
            "Epoch 19, Batch 60 loss: 0.0615365655627102\n",
            "Epoch 19, Batch 80 loss: 0.0642522727604955\n",
            "Epoch 19, Batch 100 loss: 0.0604849074967206\n",
            "Epoch 19, Batch 120 loss: 0.0594637348782271\n",
            "Epoch 19, Batch 140 loss: 0.0494008907116950\n",
            "Epoch 20, Batch 20 loss: 0.0713603939861059\n",
            "Epoch 20, Batch 40 loss: 0.0689398274756968\n",
            "Epoch 20, Batch 60 loss: 0.0447732629254460\n",
            "Epoch 20, Batch 80 loss: 0.0563714748714119\n",
            "Epoch 20, Batch 100 loss: 0.0548286496661603\n",
            "Epoch 20, Batch 120 loss: 0.0814956768415868\n",
            "Epoch 20, Batch 140 loss: 0.0857209566747770\n",
            "Epoch 21, Batch 20 loss: 0.0637026973068714\n",
            "Epoch 21, Batch 40 loss: 0.0628501732600853\n",
            "Epoch 21, Batch 60 loss: 0.0690056399675086\n",
            "Epoch 21, Batch 80 loss: 0.0603607276454568\n",
            "Epoch 21, Batch 100 loss: 0.0717881070915610\n",
            "Epoch 21, Batch 120 loss: 0.0778240098152310\n",
            "Epoch 21, Batch 140 loss: 0.0751687666866928\n",
            "Epoch 22, Batch 20 loss: 0.0672110944055021\n",
            "Epoch 22, Batch 40 loss: 0.0791551464237273\n",
            "Epoch 22, Batch 60 loss: 0.1072197429370135\n",
            "Epoch 22, Batch 80 loss: 0.0683116640429944\n",
            "Epoch 22, Batch 100 loss: 0.0606731091160327\n",
            "Epoch 22, Batch 120 loss: 0.0477214683312923\n",
            "Epoch 22, Batch 140 loss: 0.0482542242389172\n",
            "Epoch 23, Batch 20 loss: 0.0430654637282714\n",
            "Epoch 23, Batch 40 loss: 0.0562872532289475\n",
            "Epoch 23, Batch 60 loss: 0.0748838857281953\n",
            "Epoch 23, Batch 80 loss: 0.0779224599711597\n",
            "Epoch 23, Batch 100 loss: 0.0497917841188610\n",
            "Epoch 23, Batch 120 loss: 0.0523670173482969\n",
            "Epoch 23, Batch 140 loss: 0.0571395212318748\n",
            "Epoch 24, Batch 20 loss: 0.0621277678990737\n",
            "Epoch 24, Batch 40 loss: 0.0547026527812704\n",
            "Epoch 24, Batch 60 loss: 0.0573315581772476\n",
            "Epoch 24, Batch 80 loss: 0.0442021347815171\n",
            "Epoch 24, Batch 100 loss: 0.0433600479271263\n",
            "Epoch 24, Batch 120 loss: 0.0629991913214326\n",
            "Epoch 24, Batch 140 loss: 0.0680700127035379\n",
            "Epoch 25, Batch 20 loss: 0.0592569542815909\n",
            "Epoch 25, Batch 40 loss: 0.0698780862614512\n",
            "Epoch 25, Batch 60 loss: 0.0375793490093201\n",
            "Epoch 25, Batch 80 loss: 0.0486262639518827\n",
            "Epoch 25, Batch 100 loss: 0.0477657977025956\n",
            "Epoch 25, Batch 120 loss: 0.0445301574538462\n",
            "Epoch 25, Batch 140 loss: 0.0469006283208728\n",
            "Epoch 26, Batch 20 loss: 0.0529297126457095\n",
            "Epoch 26, Batch 40 loss: 0.0585708865430206\n",
            "Epoch 26, Batch 60 loss: 0.0340364330681041\n",
            "Epoch 26, Batch 80 loss: 0.0359877698821947\n",
            "Epoch 26, Batch 100 loss: 0.0620899610221386\n",
            "Epoch 26, Batch 120 loss: 0.0544267086312175\n",
            "Epoch 26, Batch 140 loss: 0.0454090988729149\n",
            "Epoch 27, Batch 20 loss: 0.0548313877079636\n",
            "Epoch 27, Batch 40 loss: 0.0512128659989685\n",
            "Epoch 27, Batch 60 loss: 0.0467556411167607\n",
            "Epoch 27, Batch 80 loss: 0.0572090152883902\n",
            "Epoch 27, Batch 100 loss: 0.0644821570720524\n",
            "Epoch 27, Batch 120 loss: 0.0659000280313194\n",
            "Epoch 27, Batch 140 loss: 0.0367230980889872\n",
            "Epoch 28, Batch 20 loss: 0.0408411252079532\n",
            "Epoch 28, Batch 40 loss: 0.0507117856759578\n",
            "Epoch 28, Batch 60 loss: 0.0485864787595347\n",
            "Epoch 28, Batch 80 loss: 0.0578958985162899\n",
            "Epoch 28, Batch 100 loss: 0.0482920252252370\n",
            "Epoch 28, Batch 120 loss: 0.0615502543281764\n",
            "Epoch 28, Batch 140 loss: 0.0443145690020174\n",
            "Epoch 29, Batch 20 loss: 0.0610592035576701\n",
            "Epoch 29, Batch 40 loss: 0.0475817865924910\n",
            "Epoch 29, Batch 60 loss: 0.0752680559642613\n",
            "Epoch 29, Batch 80 loss: 0.0430851156823337\n",
            "Epoch 29, Batch 100 loss: 0.0568370054941624\n",
            "Epoch 29, Batch 120 loss: 0.0537292230175808\n",
            "Epoch 29, Batch 140 loss: 0.0832306256052107\n",
            "Epoch 30, Batch 20 loss: 0.0446981190703809\n",
            "Epoch 30, Batch 40 loss: 0.0403812611708418\n",
            "Epoch 30, Batch 60 loss: 0.0461839477065951\n",
            "Epoch 30, Batch 80 loss: 0.0729120409581810\n",
            "Epoch 30, Batch 100 loss: 0.0510325693991035\n",
            "Epoch 30, Batch 120 loss: 0.0462624088861048\n",
            "Epoch 30, Batch 140 loss: 0.0398376684403047\n",
            "Epoch 31, Batch 20 loss: 0.0256777400267310\n",
            "Epoch 31, Batch 40 loss: 0.0595495333895087\n",
            "Epoch 31, Batch 60 loss: 0.0601636907318607\n",
            "Epoch 31, Batch 80 loss: 0.0480573602020741\n",
            "Epoch 31, Batch 100 loss: 0.0291720288805664\n",
            "Epoch 31, Batch 120 loss: 0.0394622558727860\n",
            "Epoch 31, Batch 140 loss: 0.0351042418740690\n",
            "Epoch 32, Batch 20 loss: 0.0448170091025531\n",
            "Epoch 32, Batch 40 loss: 0.0299185806652531\n",
            "Epoch 32, Batch 60 loss: 0.0341137050185353\n",
            "Epoch 32, Batch 80 loss: 0.0378153360681608\n",
            "Epoch 32, Batch 100 loss: 0.0305467005353421\n",
            "Epoch 32, Batch 120 loss: 0.0373994653811678\n",
            "Epoch 32, Batch 140 loss: 0.0360173459863290\n",
            "Epoch 33, Batch 20 loss: 0.0432975225616246\n",
            "Epoch 33, Batch 40 loss: 0.0360039688413963\n",
            "Epoch 33, Batch 60 loss: 0.0547638140851632\n",
            "Epoch 33, Batch 80 loss: 0.0696459077065811\n",
            "Epoch 33, Batch 100 loss: 0.0364418143872172\n",
            "Epoch 33, Batch 120 loss: 0.0484329279046506\n",
            "Epoch 33, Batch 140 loss: 0.0337646296480671\n",
            "Epoch 34, Batch 20 loss: 0.0389085418311879\n",
            "Epoch 34, Batch 40 loss: 0.0596479354426265\n",
            "Epoch 34, Batch 60 loss: 0.0501382591668516\n",
            "Epoch 34, Batch 80 loss: 0.0561288990778849\n",
            "Epoch 34, Batch 100 loss: 0.0328786327736452\n",
            "Epoch 34, Batch 120 loss: 0.0733068168163300\n",
            "Epoch 34, Batch 140 loss: 0.0479767523240298\n",
            "Epoch 35, Batch 20 loss: 0.0262548946775496\n",
            "Epoch 35, Batch 40 loss: 0.0755188407609239\n",
            "Epoch 35, Batch 60 loss: 0.0335961962817237\n",
            "Epoch 35, Batch 80 loss: 0.0365552645875141\n",
            "Epoch 35, Batch 100 loss: 0.0421974247321486\n",
            "Epoch 35, Batch 120 loss: 0.0381872090278193\n",
            "Epoch 35, Batch 140 loss: 0.0362394748488441\n",
            "Epoch 36, Batch 20 loss: 0.0328535863664001\n",
            "Epoch 36, Batch 40 loss: 0.0282444220967591\n",
            "Epoch 36, Batch 60 loss: 0.0247336893808097\n",
            "Epoch 36, Batch 80 loss: 0.0348936109337956\n",
            "Epoch 36, Batch 100 loss: 0.0379312566015869\n",
            "Epoch 36, Batch 120 loss: 0.0374876294517890\n",
            "Epoch 36, Batch 140 loss: 0.0361931297928095\n",
            "Epoch 37, Batch 20 loss: 0.0462761780945584\n",
            "Epoch 37, Batch 40 loss: 0.0419217089656740\n",
            "Epoch 37, Batch 60 loss: 0.0509607336949557\n",
            "Epoch 37, Batch 80 loss: 0.0429402727866545\n",
            "Epoch 37, Batch 100 loss: 0.0509828836191446\n",
            "Epoch 37, Batch 120 loss: 0.0317938484717160\n",
            "Epoch 37, Batch 140 loss: 0.0238353704567999\n",
            "Epoch 38, Batch 20 loss: 0.0516374005936086\n",
            "Epoch 38, Batch 40 loss: 0.0609948353841901\n",
            "Epoch 38, Batch 60 loss: 0.0420893646543846\n",
            "Epoch 38, Batch 80 loss: 0.0372277191840112\n",
            "Epoch 38, Batch 100 loss: 0.0430139250122011\n",
            "Epoch 38, Batch 120 loss: 0.0295977562665939\n",
            "Epoch 38, Batch 140 loss: 0.0428446479141712\n",
            "Epoch 39, Batch 20 loss: 0.0501978039275855\n",
            "Epoch 39, Batch 40 loss: 0.0500294488389045\n",
            "Epoch 39, Batch 60 loss: 0.0452423206530511\n",
            "Epoch 39, Batch 80 loss: 0.0200317723909393\n",
            "Epoch 39, Batch 100 loss: 0.0587673040572554\n",
            "Epoch 39, Batch 120 loss: 0.0609756355173886\n",
            "Epoch 39, Batch 140 loss: 0.0535379142500460\n",
            "Epoch 40, Batch 20 loss: 0.0479430106235668\n",
            "Epoch 40, Batch 40 loss: 0.0583582384977490\n",
            "Epoch 40, Batch 60 loss: 0.0321097445208579\n",
            "Epoch 40, Batch 80 loss: 0.0194373347330838\n",
            "Epoch 40, Batch 100 loss: 0.0356452653417364\n",
            "Epoch 40, Batch 120 loss: 0.0276513354852796\n",
            "Epoch 40, Batch 140 loss: 0.0282246999908239\n",
            "Epoch 41, Batch 20 loss: 0.0434336656471714\n",
            "Epoch 41, Batch 40 loss: 0.0230325305950828\n",
            "Epoch 41, Batch 60 loss: 0.0288459653034806\n",
            "Epoch 41, Batch 80 loss: 0.0442862323718145\n",
            "Epoch 41, Batch 100 loss: 0.0357205521548167\n",
            "Epoch 41, Batch 120 loss: 0.0336828920990229\n",
            "Epoch 41, Batch 140 loss: 0.0350655319401994\n",
            "Epoch 42, Batch 20 loss: 0.0431339577306062\n",
            "Epoch 42, Batch 40 loss: 0.0512142076157033\n",
            "Epoch 42, Batch 60 loss: 0.0437370977597311\n",
            "Epoch 42, Batch 80 loss: 0.0327202104264870\n",
            "Epoch 42, Batch 100 loss: 0.0495089153759182\n",
            "Epoch 42, Batch 120 loss: 0.0254245846066624\n",
            "Epoch 42, Batch 140 loss: 0.0425663917791098\n",
            "Epoch 43, Batch 20 loss: 0.0221648541744798\n",
            "Epoch 43, Batch 40 loss: 0.0473749454598874\n",
            "Epoch 43, Batch 60 loss: 0.0463882653508335\n",
            "Epoch 43, Batch 80 loss: 0.0375644760206342\n",
            "Epoch 43, Batch 100 loss: 0.0306036071386188\n",
            "Epoch 43, Batch 120 loss: 0.0646104390034452\n",
            "Epoch 43, Batch 140 loss: 0.0325352142332122\n",
            "Epoch 44, Batch 20 loss: 0.0252884479355998\n",
            "Epoch 44, Batch 40 loss: 0.0277601115754805\n",
            "Epoch 44, Batch 60 loss: 0.0577711311634630\n",
            "Epoch 44, Batch 80 loss: 0.0441790395881981\n",
            "Epoch 44, Batch 100 loss: 0.0409727570135146\n",
            "Epoch 44, Batch 120 loss: 0.0415123411687091\n",
            "Epoch 44, Batch 140 loss: 0.0421090067829937\n",
            "Epoch 45, Batch 20 loss: 0.0370350336655974\n",
            "Epoch 45, Batch 40 loss: 0.0582176885101944\n",
            "Epoch 45, Batch 60 loss: 0.0275083380751312\n",
            "Epoch 45, Batch 80 loss: 0.0356620085192844\n",
            "Epoch 45, Batch 100 loss: 0.0288970613619313\n",
            "Epoch 45, Batch 120 loss: 0.0525991229806095\n",
            "Epoch 45, Batch 140 loss: 0.0457172345020808\n",
            "Epoch 46, Batch 20 loss: 0.0376290959306061\n",
            "Epoch 46, Batch 40 loss: 0.0373682169709355\n",
            "Epoch 46, Batch 60 loss: 0.0535527912550606\n",
            "Epoch 46, Batch 80 loss: 0.0508196552749723\n",
            "Epoch 46, Batch 100 loss: 0.0465951213147491\n",
            "Epoch 46, Batch 120 loss: 0.0480226072715595\n",
            "Epoch 46, Batch 140 loss: 0.0686682805418968\n",
            "Epoch 47, Batch 20 loss: 0.0327216179575771\n",
            "Epoch 47, Batch 40 loss: 0.0257283367449418\n",
            "Epoch 47, Batch 60 loss: 0.0208697218913585\n",
            "Epoch 47, Batch 80 loss: 0.0268452298245393\n",
            "Epoch 47, Batch 100 loss: 0.0592477205907926\n",
            "Epoch 47, Batch 120 loss: 0.0557401892263442\n",
            "Epoch 47, Batch 140 loss: 0.0388684385223314\n",
            "Epoch 48, Batch 20 loss: 0.0273068804526702\n",
            "Epoch 48, Batch 40 loss: 0.0399913056753576\n",
            "Epoch 48, Batch 60 loss: 0.0507279047276825\n",
            "Epoch 48, Batch 80 loss: 0.0421495911898091\n",
            "Epoch 48, Batch 100 loss: 0.0358094410970807\n",
            "Epoch 48, Batch 120 loss: 0.0476624932372943\n",
            "Epoch 48, Batch 140 loss: 0.0327788345050067\n",
            "Epoch 49, Batch 20 loss: 0.0380086766323075\n",
            "Epoch 49, Batch 40 loss: 0.0421533042564988\n",
            "Epoch 49, Batch 60 loss: 0.0385712021030486\n",
            "Epoch 49, Batch 80 loss: 0.0304035655688494\n",
            "Epoch 49, Batch 100 loss: 0.0573097393848002\n",
            "Epoch 49, Batch 120 loss: 0.0366276721470058\n",
            "Epoch 49, Batch 140 loss: 0.0295151556842029\n",
            "Epoch 50, Batch 20 loss: 0.0168153711827472\n",
            "Epoch 50, Batch 40 loss: 0.0623649120097980\n",
            "Epoch 50, Batch 60 loss: 0.0292648556642234\n",
            "Epoch 50, Batch 80 loss: 0.0591252944665030\n",
            "Epoch 50, Batch 100 loss: 0.0240579559700564\n",
            "Epoch 50, Batch 120 loss: 0.0328049782197922\n",
            "Epoch 50, Batch 140 loss: 0.0403360735392198\n",
            "Epoch 51, Batch 20 loss: 0.0544528581667691\n",
            "Epoch 51, Batch 40 loss: 0.0233211382757872\n",
            "Epoch 51, Batch 60 loss: 0.0447653492214158\n",
            "Epoch 51, Batch 80 loss: 0.0579872844042256\n",
            "Epoch 51, Batch 100 loss: 0.0434512752573937\n",
            "Epoch 51, Batch 120 loss: 0.0396238776389509\n",
            "Epoch 51, Batch 140 loss: 0.0629022968001664\n",
            "Epoch 52, Batch 20 loss: 0.0317490067565814\n",
            "Epoch 52, Batch 40 loss: 0.0466554530663416\n",
            "Epoch 52, Batch 60 loss: 0.0263214709004387\n",
            "Epoch 52, Batch 80 loss: 0.0235252769198269\n",
            "Epoch 52, Batch 100 loss: 0.0443684203084558\n",
            "Epoch 52, Batch 120 loss: 0.0238307004328817\n",
            "Epoch 52, Batch 140 loss: 0.0454728295560926\n",
            "Epoch 53, Batch 20 loss: 0.0253686031326652\n",
            "Epoch 53, Batch 40 loss: 0.0401182968635112\n",
            "Epoch 53, Batch 60 loss: 0.0312214364763349\n",
            "Epoch 53, Batch 80 loss: 0.0893694596365094\n",
            "Epoch 53, Batch 100 loss: 0.0362612274708226\n",
            "Epoch 53, Batch 120 loss: 0.0395429971744306\n",
            "Epoch 53, Batch 140 loss: 0.0451195589732379\n",
            "Epoch 54, Batch 20 loss: 0.0526514442637563\n",
            "Epoch 54, Batch 40 loss: 0.0379851285950281\n",
            "Epoch 54, Batch 60 loss: 0.0250930167734623\n",
            "Epoch 54, Batch 80 loss: 0.0468744629994035\n",
            "Epoch 54, Batch 100 loss: 0.0484421992441639\n",
            "Epoch 54, Batch 120 loss: 0.0405105524696410\n",
            "Epoch 54, Batch 140 loss: 0.0373160243732855\n",
            "Epoch 55, Batch 20 loss: 0.0259530791779980\n",
            "Epoch 55, Batch 40 loss: 0.0549035375937819\n",
            "Epoch 55, Batch 60 loss: 0.0530076418071985\n",
            "Epoch 55, Batch 80 loss: 0.0288924018619582\n",
            "Epoch 55, Batch 100 loss: 0.0389239878160879\n",
            "Epoch 55, Batch 120 loss: 0.0668852622387931\n",
            "Epoch 55, Batch 140 loss: 0.0406262459931895\n",
            "Epoch 56, Batch 20 loss: 0.0311498590279371\n",
            "Epoch 56, Batch 40 loss: 0.0403012077789754\n",
            "Epoch 56, Batch 60 loss: 0.0539235047530383\n",
            "Epoch 56, Batch 80 loss: 0.0551279379520565\n",
            "Epoch 56, Batch 100 loss: 0.0384677527472377\n",
            "Epoch 56, Batch 120 loss: 0.0335065580671653\n",
            "Epoch 56, Batch 140 loss: 0.0683940368006006\n",
            "Epoch 57, Batch 20 loss: 0.0476777551695704\n",
            "Epoch 57, Batch 40 loss: 0.0300753630464897\n",
            "Epoch 57, Batch 60 loss: 0.0404993925243616\n",
            "Epoch 57, Batch 80 loss: 0.0326688126660883\n",
            "Epoch 57, Batch 100 loss: 0.0673065763432533\n",
            "Epoch 57, Batch 120 loss: 0.0446636465378106\n",
            "Epoch 57, Batch 140 loss: 0.0404878134373575\n",
            "Epoch 58, Batch 20 loss: 0.0558385421289131\n",
            "Epoch 58, Batch 40 loss: 0.0316940226359293\n",
            "Epoch 58, Batch 60 loss: 0.0412070296239108\n",
            "Epoch 58, Batch 80 loss: 0.0422502583125606\n",
            "Epoch 58, Batch 100 loss: 0.0306824577972293\n",
            "Epoch 58, Batch 120 loss: 0.0414745933376253\n",
            "Epoch 58, Batch 140 loss: 0.0761495334794745\n",
            "Epoch 59, Batch 20 loss: 0.0498711492167786\n",
            "Epoch 59, Batch 40 loss: 0.0442587345140055\n",
            "Epoch 59, Batch 60 loss: 0.0371118735987693\n",
            "Epoch 59, Batch 80 loss: 0.0299568315036595\n",
            "Epoch 59, Batch 100 loss: 0.0400382613763213\n",
            "Epoch 59, Batch 120 loss: 0.0306457038968801\n",
            "Epoch 59, Batch 140 loss: 0.0414798217359930\n",
            "Epoch 60, Batch 20 loss: 0.0368563400348648\n",
            "Epoch 60, Batch 40 loss: 0.0409744570031762\n",
            "Epoch 60, Batch 60 loss: 0.0272350743296556\n",
            "Epoch 60, Batch 80 loss: 0.0413914622738957\n",
            "Epoch 60, Batch 100 loss: 0.0471029937500134\n",
            "Epoch 60, Batch 120 loss: 0.0306481799809262\n",
            "Epoch 60, Batch 140 loss: 0.0347692813724279\n",
            "Epoch 61, Batch 20 loss: 0.0421687665628269\n",
            "Epoch 61, Batch 40 loss: 0.0299458656227216\n",
            "Epoch 61, Batch 60 loss: 0.0325849422486499\n",
            "Epoch 61, Batch 80 loss: 0.0289232622832060\n",
            "Epoch 61, Batch 100 loss: 0.0609520295169204\n",
            "Epoch 61, Batch 120 loss: 0.0357755717355758\n",
            "Epoch 61, Batch 140 loss: 0.0371263896580786\n",
            "Epoch 62, Batch 20 loss: 0.0437986896140501\n",
            "Epoch 62, Batch 40 loss: 0.0237203910131939\n",
            "Epoch 62, Batch 60 loss: 0.0325869832187891\n",
            "Epoch 62, Batch 80 loss: 0.0261773890117183\n",
            "Epoch 62, Batch 100 loss: 0.0304889970924705\n",
            "Epoch 62, Batch 120 loss: 0.0548717667115852\n",
            "Epoch 62, Batch 140 loss: 0.0449309639632702\n",
            "Epoch 63, Batch 20 loss: 0.0404246612684801\n",
            "Epoch 63, Batch 40 loss: 0.0364102688618004\n",
            "Epoch 63, Batch 60 loss: 0.0466234223917127\n",
            "Epoch 63, Batch 80 loss: 0.0471141518559307\n",
            "Epoch 63, Batch 100 loss: 0.0428770286962390\n",
            "Epoch 63, Batch 120 loss: 0.0566016795579344\n",
            "Epoch 63, Batch 140 loss: 0.0354384811595082\n",
            "Epoch 64, Batch 20 loss: 0.0361812294460833\n",
            "Epoch 64, Batch 40 loss: 0.0267914042575285\n",
            "Epoch 64, Batch 60 loss: 0.0330502813216299\n",
            "Epoch 64, Batch 80 loss: 0.0395427252631635\n",
            "Epoch 64, Batch 100 loss: 0.0429515696829185\n",
            "Epoch 64, Batch 120 loss: 0.0302566158352420\n",
            "Epoch 64, Batch 140 loss: 0.0385981404921040\n",
            "Epoch 65, Batch 20 loss: 0.0925443353131414\n",
            "Epoch 65, Batch 40 loss: 0.0277546849101782\n",
            "Epoch 65, Batch 60 loss: 0.0344097284832969\n",
            "Epoch 65, Batch 80 loss: 0.0413304342422634\n",
            "Epoch 65, Batch 100 loss: 0.0483134304173291\n",
            "Epoch 65, Batch 120 loss: 0.0321114496677183\n",
            "Epoch 65, Batch 140 loss: 0.0275998508092016\n",
            "Epoch 66, Batch 20 loss: 0.0451302414527163\n",
            "Epoch 66, Batch 40 loss: 0.0305192307219841\n",
            "Epoch 66, Batch 60 loss: 0.0328323207097128\n",
            "Epoch 66, Batch 80 loss: 0.0255746337817982\n",
            "Epoch 66, Batch 100 loss: 0.0399750194977969\n",
            "Epoch 66, Batch 120 loss: 0.0461091763805598\n",
            "Epoch 66, Batch 140 loss: 0.0284493145067245\n",
            "Epoch 67, Batch 20 loss: 0.0334655917366035\n",
            "Epoch 67, Batch 40 loss: 0.0272748965304345\n",
            "Epoch 67, Batch 60 loss: 0.0357127507217228\n",
            "Epoch 67, Batch 80 loss: 0.0411566749680787\n",
            "Epoch 67, Batch 100 loss: 0.0374403659021482\n",
            "Epoch 67, Batch 120 loss: 0.0392507292330265\n",
            "Epoch 67, Batch 140 loss: 0.0582308358047158\n",
            "Epoch 68, Batch 20 loss: 0.0387691598152742\n",
            "Epoch 68, Batch 40 loss: 0.0223492372548208\n",
            "Epoch 68, Batch 60 loss: 0.0580052625155076\n",
            "Epoch 68, Batch 80 loss: 0.0498854857403785\n",
            "Epoch 68, Batch 100 loss: 0.0517336488468573\n",
            "Epoch 68, Batch 120 loss: 0.0241223122691736\n",
            "Epoch 68, Batch 140 loss: 0.0338033020030707\n",
            "Epoch 69, Batch 20 loss: 0.0424066605977714\n",
            "Epoch 69, Batch 40 loss: 0.0317260556388646\n",
            "Epoch 69, Batch 60 loss: 0.0318799725850113\n",
            "Epoch 69, Batch 80 loss: 0.0431426748866215\n",
            "Epoch 69, Batch 100 loss: 0.0460633241804317\n",
            "Epoch 69, Batch 120 loss: 0.0328895638231188\n",
            "Epoch 69, Batch 140 loss: 0.0362078136065975\n",
            "Epoch 70, Batch 20 loss: 0.0357655212283134\n",
            "Epoch 70, Batch 40 loss: 0.0406013772822916\n",
            "Epoch 70, Batch 60 loss: 0.0327051701024175\n",
            "Epoch 70, Batch 80 loss: 0.0456698182038963\n",
            "Epoch 70, Batch 100 loss: 0.0492139869136736\n",
            "Epoch 70, Batch 120 loss: 0.0383582065114751\n",
            "Epoch 70, Batch 140 loss: 0.0293035966926254\n",
            "Epoch 71, Batch 20 loss: 0.0324484397424385\n",
            "Epoch 71, Batch 40 loss: 0.0379556197091006\n",
            "Epoch 71, Batch 60 loss: 0.0370041911490262\n",
            "Epoch 71, Batch 80 loss: 0.0336022999137640\n",
            "Epoch 71, Batch 100 loss: 0.0420968924998306\n",
            "Epoch 71, Batch 120 loss: 0.0264960635453463\n",
            "Epoch 71, Batch 140 loss: 0.0211357398424298\n",
            "Epoch 72, Batch 20 loss: 0.0310290497029200\n",
            "Epoch 72, Batch 40 loss: 0.0236364981625229\n",
            "Epoch 72, Batch 60 loss: 0.0352913410402834\n",
            "Epoch 72, Batch 80 loss: 0.0478489296510816\n",
            "Epoch 72, Batch 100 loss: 0.0397165972972289\n",
            "Epoch 72, Batch 120 loss: 0.0320586436660960\n",
            "Epoch 72, Batch 140 loss: 0.0324424354592338\n",
            "Epoch 73, Batch 20 loss: 0.0476153626572341\n",
            "Epoch 73, Batch 40 loss: 0.0260998314945027\n",
            "Epoch 73, Batch 60 loss: 0.0518211535643786\n",
            "Epoch 73, Batch 80 loss: 0.0484630144434050\n",
            "Epoch 73, Batch 100 loss: 0.0441762383561581\n",
            "Epoch 73, Batch 120 loss: 0.0200611351756379\n",
            "Epoch 73, Batch 140 loss: 0.0313684854074381\n",
            "Epoch 74, Batch 20 loss: 0.0421951160766184\n",
            "Epoch 74, Batch 40 loss: 0.0280777012114413\n",
            "Epoch 74, Batch 60 loss: 0.0435167635325342\n",
            "Epoch 74, Batch 80 loss: 0.0300069562392309\n",
            "Epoch 74, Batch 100 loss: 0.0269750511972234\n",
            "Epoch 74, Batch 120 loss: 0.0293323023477569\n",
            "Epoch 74, Batch 140 loss: 0.0361088477191515\n",
            "Epoch 75, Batch 20 loss: 0.0466371246846393\n",
            "Epoch 75, Batch 40 loss: 0.0448202604195103\n",
            "Epoch 75, Batch 60 loss: 0.0330891283228993\n",
            "Epoch 75, Batch 80 loss: 0.0334585256059654\n",
            "Epoch 75, Batch 100 loss: 0.0356277370126918\n",
            "Epoch 75, Batch 120 loss: 0.0261702385963872\n",
            "Epoch 75, Batch 140 loss: 0.0384799007559195\n",
            "Epoch 76, Batch 20 loss: 0.0309771416708827\n",
            "Epoch 76, Batch 40 loss: 0.0684664806001820\n",
            "Epoch 76, Batch 60 loss: 0.0486087565310299\n",
            "Epoch 76, Batch 80 loss: 0.0489790525054559\n",
            "Epoch 76, Batch 100 loss: 0.0335188672645017\n",
            "Epoch 76, Batch 120 loss: 0.0326096020871773\n",
            "Epoch 76, Batch 140 loss: 0.0440395515644923\n",
            "Epoch 77, Batch 20 loss: 0.0493497703457251\n",
            "Epoch 77, Batch 40 loss: 0.0362705040024593\n",
            "Epoch 77, Batch 60 loss: 0.0339181622490287\n",
            "Epoch 77, Batch 80 loss: 0.0376377516193315\n",
            "Epoch 77, Batch 100 loss: 0.0280114935012534\n",
            "Epoch 77, Batch 120 loss: 0.0363122405949980\n",
            "Epoch 77, Batch 140 loss: 0.0428250164724886\n",
            "Epoch 78, Batch 20 loss: 0.0341811761027202\n",
            "Epoch 78, Batch 40 loss: 0.0382699177716859\n",
            "Epoch 78, Batch 60 loss: 0.0421865753596649\n",
            "Epoch 78, Batch 80 loss: 0.0351719998288900\n",
            "Epoch 78, Batch 100 loss: 0.0513782498659566\n",
            "Epoch 78, Batch 120 loss: 0.0426192849874496\n",
            "Epoch 78, Batch 140 loss: 0.0436929332325235\n",
            "Epoch 79, Batch 20 loss: 0.0280994003056549\n",
            "Epoch 79, Batch 40 loss: 0.0517516429652460\n",
            "Epoch 79, Batch 60 loss: 0.0445733476430178\n",
            "Epoch 79, Batch 80 loss: 0.0317060555447824\n",
            "Epoch 79, Batch 100 loss: 0.0342332748696208\n",
            "Epoch 79, Batch 120 loss: 0.0348791822791100\n",
            "Epoch 79, Batch 140 loss: 0.0524241317063570\n",
            "Epoch 80, Batch 20 loss: 0.0423305013915524\n",
            "Epoch 80, Batch 40 loss: 0.0616621634457260\n",
            "Epoch 80, Batch 60 loss: 0.0210337661206722\n",
            "Epoch 80, Batch 80 loss: 0.0374226717045531\n",
            "Epoch 80, Batch 100 loss: 0.0291797010460868\n",
            "Epoch 80, Batch 120 loss: 0.0235500349197537\n",
            "Epoch 80, Batch 140 loss: 0.0355194106232375\n",
            "Epoch 81, Batch 20 loss: 0.0303284646011889\n",
            "Epoch 81, Batch 40 loss: 0.0357961261877790\n",
            "Epoch 81, Batch 60 loss: 0.0232560412958264\n",
            "Epoch 81, Batch 80 loss: 0.0392978286603466\n",
            "Epoch 81, Batch 100 loss: 0.0327317194547504\n",
            "Epoch 81, Batch 120 loss: 0.0534055445576087\n",
            "Epoch 81, Batch 140 loss: 0.0432779257418588\n",
            "Epoch 82, Batch 20 loss: 0.0232764991465956\n",
            "Epoch 82, Batch 40 loss: 0.0371262397849932\n",
            "Epoch 82, Batch 60 loss: 0.0293244319967926\n",
            "Epoch 82, Batch 80 loss: 0.0518928706645966\n",
            "Epoch 82, Batch 100 loss: 0.0367211510660127\n",
            "Epoch 82, Batch 120 loss: 0.0346475833794102\n",
            "Epoch 82, Batch 140 loss: 0.0383699381724000\n",
            "Epoch 83, Batch 20 loss: 0.0387586890603416\n",
            "Epoch 83, Batch 40 loss: 0.0316143011907116\n",
            "Epoch 83, Batch 60 loss: 0.0364043679088354\n",
            "Epoch 83, Batch 80 loss: 0.0294128737645224\n",
            "Epoch 83, Batch 100 loss: 0.0223846682813019\n",
            "Epoch 83, Batch 120 loss: 0.0370970561518334\n",
            "Epoch 83, Batch 140 loss: 0.0421187131898478\n",
            "Epoch 84, Batch 20 loss: 0.0276332461507991\n",
            "Epoch 84, Batch 40 loss: 0.0410645923344418\n",
            "Epoch 84, Batch 60 loss: 0.0310436011292040\n",
            "Epoch 84, Batch 80 loss: 0.0291236562887207\n",
            "Epoch 84, Batch 100 loss: 0.0392457130830735\n",
            "Epoch 84, Batch 120 loss: 0.0185344503261149\n",
            "Epoch 84, Batch 140 loss: 0.0488282767590135\n",
            "Epoch 85, Batch 20 loss: 0.0363020649878308\n",
            "Epoch 85, Batch 40 loss: 0.0330713530769572\n",
            "Epoch 85, Batch 60 loss: 0.0348548744572327\n",
            "Epoch 85, Batch 80 loss: 0.0336639952380210\n",
            "Epoch 85, Batch 100 loss: 0.0334254480665550\n",
            "Epoch 85, Batch 120 loss: 0.0345746860839427\n",
            "Epoch 85, Batch 140 loss: 0.0327740592067130\n",
            "Epoch 86, Batch 20 loss: 0.0388775228057057\n",
            "Epoch 86, Batch 40 loss: 0.0568170881364495\n",
            "Epoch 86, Batch 60 loss: 0.0350809875875711\n",
            "Epoch 86, Batch 80 loss: 0.0210528547409922\n",
            "Epoch 86, Batch 100 loss: 0.0388784214621410\n",
            "Epoch 86, Batch 120 loss: 0.0438635241822340\n",
            "Epoch 86, Batch 140 loss: 0.0344372409395874\n",
            "Epoch 87, Batch 20 loss: 0.0419014877639711\n",
            "Epoch 87, Batch 40 loss: 0.0321898770984262\n",
            "Epoch 87, Batch 60 loss: 0.0238989210454747\n",
            "Epoch 87, Batch 80 loss: 0.0442444448126480\n",
            "Epoch 87, Batch 100 loss: 0.0358523371396586\n",
            "Epoch 87, Batch 120 loss: 0.0397424543742090\n",
            "Epoch 87, Batch 140 loss: 0.0193491073674522\n",
            "Epoch 88, Batch 20 loss: 0.0262452403665520\n",
            "Epoch 88, Batch 40 loss: 0.0610602589324117\n",
            "Epoch 88, Batch 60 loss: 0.0541260302765295\n",
            "Epoch 88, Batch 80 loss: 0.0278948851162568\n",
            "Epoch 88, Batch 100 loss: 0.0425066782394424\n",
            "Epoch 88, Batch 120 loss: 0.0279393497854471\n",
            "Epoch 88, Batch 140 loss: 0.0326298078754917\n",
            "Epoch 89, Batch 20 loss: 0.0440569668076932\n",
            "Epoch 89, Batch 40 loss: 0.0223459740867838\n",
            "Epoch 89, Batch 60 loss: 0.0499342955183238\n",
            "Epoch 89, Batch 80 loss: 0.0305219487287104\n",
            "Epoch 89, Batch 100 loss: 0.0321884742472321\n",
            "Epoch 89, Batch 120 loss: 0.0380770587129518\n",
            "Epoch 89, Batch 140 loss: 0.0309964847983792\n",
            "Epoch 90, Batch 20 loss: 0.0469363603275269\n",
            "Epoch 90, Batch 40 loss: 0.0269149843836203\n",
            "Epoch 90, Batch 60 loss: 0.0485482075950131\n",
            "Epoch 90, Batch 80 loss: 0.0352675750618801\n",
            "Epoch 90, Batch 100 loss: 0.0400867864489555\n",
            "Epoch 90, Batch 120 loss: 0.0317028176970780\n",
            "Epoch 90, Batch 140 loss: 0.0483069864567369\n",
            "Epoch 91, Batch 20 loss: 0.0428903334774077\n",
            "Epoch 91, Batch 40 loss: 0.0200583038851619\n",
            "Epoch 91, Batch 60 loss: 0.0292700402904302\n",
            "Epoch 91, Batch 80 loss: 0.0285467630485073\n",
            "Epoch 91, Batch 100 loss: 0.0309228235855699\n",
            "Epoch 91, Batch 120 loss: 0.0497236819937825\n",
            "Epoch 91, Batch 140 loss: 0.0547559569822624\n",
            "Epoch 92, Batch 20 loss: 0.0509846508270130\n",
            "Epoch 92, Batch 40 loss: 0.0331705274409615\n",
            "Epoch 92, Batch 60 loss: 0.0306450960226357\n",
            "Epoch 92, Batch 80 loss: 0.0380774816498160\n",
            "Epoch 92, Batch 100 loss: 0.0414752864046022\n",
            "Epoch 92, Batch 120 loss: 0.0341056239791214\n",
            "Epoch 92, Batch 140 loss: 0.0387291510705836\n",
            "Epoch 93, Batch 20 loss: 0.0359842081146780\n",
            "Epoch 93, Batch 40 loss: 0.0323006420396268\n",
            "Epoch 93, Batch 60 loss: 0.0329288074281067\n",
            "Epoch 93, Batch 80 loss: 0.0198185236426070\n",
            "Epoch 93, Batch 100 loss: 0.0265920148463920\n",
            "Epoch 93, Batch 120 loss: 0.0364723315928131\n",
            "Epoch 93, Batch 140 loss: 0.0288314065430313\n",
            "Epoch 94, Batch 20 loss: 0.0541234301635996\n",
            "Epoch 94, Batch 40 loss: 0.0698855534661561\n",
            "Epoch 94, Batch 60 loss: 0.0265206483192742\n",
            "Epoch 94, Batch 80 loss: 0.0286717574112117\n",
            "Epoch 94, Batch 100 loss: 0.0378909460268915\n",
            "Epoch 94, Batch 120 loss: 0.0271502073854208\n",
            "Epoch 94, Batch 140 loss: 0.0463497010874562\n",
            "Epoch 95, Batch 20 loss: 0.0445960733806714\n",
            "Epoch 95, Batch 40 loss: 0.0550872342195362\n",
            "Epoch 95, Batch 60 loss: 0.0435578877222724\n",
            "Epoch 95, Batch 80 loss: 0.0484577494906262\n",
            "Epoch 95, Batch 100 loss: 0.0635102327913046\n",
            "Epoch 95, Batch 120 loss: 0.0343025899492204\n",
            "Epoch 95, Batch 140 loss: 0.0286174444016069\n",
            "Epoch 96, Batch 20 loss: 0.0291940906783566\n",
            "Epoch 96, Batch 40 loss: 0.0299833117052913\n",
            "Epoch 96, Batch 60 loss: 0.0271715230657719\n",
            "Epoch 96, Batch 80 loss: 0.0397772173397243\n",
            "Epoch 96, Batch 100 loss: 0.0357099338900298\n",
            "Epoch 96, Batch 120 loss: 0.0254705408588052\n",
            "Epoch 96, Batch 140 loss: 0.0564854912227020\n",
            "Epoch 97, Batch 20 loss: 0.0499680905602872\n",
            "Epoch 97, Batch 40 loss: 0.0306113822385669\n",
            "Epoch 97, Batch 60 loss: 0.0472639963263646\n",
            "Epoch 97, Batch 80 loss: 0.0313576020183973\n",
            "Epoch 97, Batch 100 loss: 0.0331294027157128\n",
            "Epoch 97, Batch 120 loss: 0.0314269161317497\n",
            "Epoch 97, Batch 140 loss: 0.0575590326450765\n",
            "Epoch 98, Batch 20 loss: 0.0311733882874250\n",
            "Epoch 98, Batch 40 loss: 0.0213056291453540\n",
            "Epoch 98, Batch 60 loss: 0.0290045297588222\n",
            "Epoch 98, Batch 80 loss: 0.0475194500526413\n",
            "Epoch 98, Batch 100 loss: 0.0542169680120423\n",
            "Epoch 98, Batch 120 loss: 0.0401715736836195\n",
            "Epoch 98, Batch 140 loss: 0.0451243543997407\n",
            "Epoch 99, Batch 20 loss: 0.0332130518043414\n",
            "Epoch 99, Batch 40 loss: 0.0577866034815088\n",
            "Epoch 99, Batch 60 loss: 0.0364859116729349\n",
            "Epoch 99, Batch 80 loss: 0.0505084263859317\n",
            "Epoch 99, Batch 100 loss: 0.0709493997972459\n",
            "Epoch 99, Batch 120 loss: 0.0334114727564156\n",
            "Epoch 99, Batch 140 loss: 0.0367713424609974\n",
            "Epoch 100, Batch 20 loss: 0.0369371690787375\n",
            "Epoch 100, Batch 40 loss: 0.0424381614197046\n",
            "Epoch 100, Batch 60 loss: 0.0542611116077751\n",
            "Epoch 100, Batch 80 loss: 0.0444426226429641\n",
            "Epoch 100, Batch 100 loss: 0.0414169756695628\n",
            "Epoch 100, Batch 120 loss: 0.0386713265790604\n",
            "Epoch 100, Batch 140 loss: 0.0289442987646908\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "CfA7ZjLR1BZP",
        "outputId": "c227e3cc-a082-48d5-83e2-aa006c2ef42b"
      },
      "source": [
        "plt.plot(train_losses)\n",
        "plt.title(\"Training Loss\")\n",
        "plt.show()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ItLyF9dQyJFL"
      },
      "source": [
        "Testing the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGki98W3SoEW"
      },
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xNavYOynyE6d",
        "outputId": "c0439a98-04d8-4b57-f516-494d1e1f5640"
      },
      "source": [
        "# The test_model function is from model_testing python file\n",
        "test_loss, class_correct, class_total, labels, predictions = test_model(classes, inception_v3, test_loader, criterion)\n",
        "\n",
        "# Test accuracy for each hieroglyph\n",
        "for i in range(len(classes)):\n",
        "    if class_total[i] > 0:\n",
        "        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (classes[i], 100 * class_correct[i] / class_total[i], np.sum(class_correct[i]), np.sum(class_total[i])))\n",
        "    else:\n",
        "        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
        "\n",
        "# Total Test accuracy\n",
        "print(\"\\nAccuracy: {:.3%}\".format(accuracy_score(labels, predictions)))\n",
        "print(\"\\nPrecision: {:.3%}\".format(precision_score(labels, predictions, average = 'weighted')))\n",
        "print(\"\\nRecall: {:.3%}\".format(recall_score(labels, predictions, average = 'weighted')))\n",
        "print(\"\\nF1-score: {:.3%}\".format(f1_score(labels, predictions, average = 'weighted')))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.304713\n",
            "\n",
            "Test Accuracy of  Aa15: 100% ( 1/ 1)\n",
            "Test Accuracy of  Aa26: 100% ( 1/ 1)\n",
            "Test Accuracy of  Aa27:  0% ( 0/ 1)\n",
            "Test Accuracy of    D1:  0% ( 0/ 1)\n",
            "Test Accuracy of   D10:  0% ( 0/ 1)\n",
            "Test Accuracy of  D156: 100% ( 1/ 1)\n",
            "Test Accuracy of   D19: 100% ( 1/ 1)\n",
            "Test Accuracy of    D2: 100% ( 5/ 5)\n",
            "Test Accuracy of   D21: 97% (36/37)\n",
            "Test Accuracy of   D28: 100% ( 4/ 4)\n",
            "Test Accuracy of   D35: 100% (12/12)\n",
            "Test Accuracy of   D36: 100% (12/12)\n",
            "Test Accuracy of   D39: 100% ( 1/ 1)\n",
            "Test Accuracy of    D4: 100% ( 8/ 8)\n",
            "Test Accuracy of   D46: 100% (10/10)\n",
            "Test Accuracy of   D52: 100% ( 1/ 1)\n",
            "Test Accuracy of   D54: 100% ( 3/ 3)\n",
            "Test Accuracy of   D56: 100% ( 1/ 1)\n",
            "Test Accuracy of   D58: 100% ( 8/ 8)\n",
            "Test Accuracy of   D60: 100% ( 2/ 2)\n",
            "Test Accuracy of    E1: 100% ( 2/ 2)\n",
            "Test Accuracy of   E23:  0% ( 0/ 2)\n",
            "Test Accuracy of   E34: 100% (25/25)\n",
            "Test Accuracy of    E9: 50% ( 1/ 2)\n",
            "Test Accuracy of   F13: 100% ( 2/ 2)\n",
            "Test Accuracy of   F16: 100% ( 2/ 2)\n",
            "Test Accuracy of   F18: 100% ( 2/ 2)\n",
            "Test Accuracy of   F26:  0% ( 0/ 1)\n",
            "Test Accuracy of   F31: 100% ( 2/ 2)\n",
            "Test Accuracy of   F34: 100% ( 2/ 2)\n",
            "Test Accuracy of   F35: 100% ( 1/ 1)\n",
            "Test Accuracy of    F4: 100% ( 1/ 1)\n",
            "Test Accuracy of   F40: 100% ( 1/ 1)\n",
            "Test Accuracy of    F9:  0% ( 0/ 1)\n",
            "Test Accuracy of    G1: 57% ( 4/ 7)\n",
            "Test Accuracy of   G14:  0% ( 0/ 1)\n",
            "Test Accuracy of   G17: 94% (37/39)\n",
            "Test Accuracy of   G21: 100% ( 1/ 1)\n",
            "Test Accuracy of   G25: 83% ( 5/ 6)\n",
            "Test Accuracy of   G26:  0% ( 0/ 1)\n",
            "Test Accuracy of   G29:  0% ( 0/ 1)\n",
            "Test Accuracy of   G35: 25% ( 2/ 8)\n",
            "Test Accuracy of   G36: 100% ( 2/ 2)\n",
            "Test Accuracy of   G37: 100% ( 1/ 1)\n",
            "Test Accuracy of   G39: 100% ( 5/ 5)\n",
            "Test Accuracy of    G4: 50% ( 1/ 2)\n",
            "Test Accuracy of   G40: 100% ( 2/ 2)\n",
            "Test Accuracy of   G43: 100% (40/40)\n",
            "Test Accuracy of    G5: 85% ( 6/ 7)\n",
            "Test Accuracy of    G7: 100% ( 3/ 3)\n",
            "Test Accuracy of    H6: 100% ( 2/ 2)\n",
            "Test Accuracy of   I10: 100% ( 9/ 9)\n",
            "Test Accuracy of    I9: 96% (29/30)\n",
            "Test Accuracy of    L1: 100% ( 1/ 1)\n",
            "Test Accuracy of    M1: 100% ( 1/ 1)\n",
            "Test Accuracy of   M12: 100% ( 1/ 1)\n",
            "Test Accuracy of   M16: 100% ( 1/ 1)\n",
            "Test Accuracy of   M17: 95% (70/73)\n",
            "Test Accuracy of   M18: 100% ( 3/ 3)\n",
            "Test Accuracy of  M195:  0% ( 0/ 1)\n",
            "Test Accuracy of   M20: 100% ( 1/ 1)\n",
            "Test Accuracy of   M23: 100% ( 8/ 8)\n",
            "Test Accuracy of   M29: 100% ( 1/ 1)\n",
            "Test Accuracy of    M3:  0% ( 0/ 1)\n",
            "Test Accuracy of   M40: 100% ( 1/ 1)\n",
            "Test Accuracy of   M41: 100% ( 1/ 1)\n",
            "Test Accuracy of   M42: 100% ( 1/ 1)\n",
            "Test Accuracy of   M44: 50% ( 1/ 2)\n",
            "Test Accuracy of    M8: 100% ( 1/ 1)\n",
            "Test Accuracy of    N1: 100% ( 4/ 4)\n",
            "Test Accuracy of   N14: 100% ( 3/ 3)\n",
            "Test Accuracy of   N17: 100% ( 2/ 2)\n",
            "Test Accuracy of   N18: 100% ( 4/ 4)\n",
            "Test Accuracy of   N25: 100% ( 1/ 1)\n",
            "Test Accuracy of   N29: 100% ( 4/ 4)\n",
            "Test Accuracy of   N30: 100% ( 3/ 3)\n",
            "Test Accuracy of   N31: 100% ( 4/ 4)\n",
            "Test Accuracy of   N35: 100% (90/90)\n",
            "Test Accuracy of   N36:  0% ( 0/ 1)\n",
            "Test Accuracy of   N37: 66% ( 4/ 6)\n",
            "Test Accuracy of   N41: 100% ( 1/ 1)\n",
            "Test Accuracy of    N5: 60% ( 3/ 5)\n",
            "Test Accuracy of    O1: 100% ( 4/ 4)\n",
            "Test Accuracy of   O28: 100% ( 2/ 2)\n",
            "Test Accuracy of   O31: 50% ( 1/ 2)\n",
            "Test Accuracy of   O34: 75% ( 3/ 4)\n",
            "Test Accuracy of    O4: 66% ( 2/ 3)\n",
            "Test Accuracy of   O49: 100% ( 3/ 3)\n",
            "Test Accuracy of   O50: 86% (19/22)\n",
            "Test Accuracy of    P1: 100% ( 1/ 1)\n",
            "Test Accuracy of    P6: 100% ( 1/ 1)\n",
            "Test Accuracy of    P8: 50% ( 2/ 4)\n",
            "Test Accuracy of   P98: 100% ( 1/ 1)\n",
            "Test Accuracy of    Q1: 100% ( 4/ 4)\n",
            "Test Accuracy of    Q3: 100% (16/16)\n",
            "Test Accuracy of    Q7:  0% ( 0/ 1)\n",
            "Test Accuracy of    R4: 100% ( 1/ 1)\n",
            "Test Accuracy of    R8: 100% (14/14)\n",
            "Test Accuracy of   S24:  0% ( 0/ 1)\n",
            "Test Accuracy of   S28: 100% ( 1/ 1)\n",
            "Test Accuracy of   S29: 100% (53/53)\n",
            "Test Accuracy of   S34: 100% ( 2/ 2)\n",
            "Test Accuracy of   T20: 100% ( 1/ 1)\n",
            "Test Accuracy of   T21: 100% ( 1/ 1)\n",
            "Test Accuracy of   T22: 100% ( 2/ 2)\n",
            "Test Accuracy of   T28:  0% ( 0/ 1)\n",
            "Test Accuracy of   T30:  0% ( 0/ 1)\n",
            "Test Accuracy of    U1: 100% ( 5/ 5)\n",
            "Test Accuracy of   U15: 100% ( 3/ 3)\n",
            "Test Accuracy of   U28:  0% ( 0/ 1)\n",
            "Test Accuracy of   U33: 75% ( 3/ 4)\n",
            "Test Accuracy of    U7: 100% ( 1/ 1)\n",
            "Test Accuracy of   V13: 100% (16/16)\n",
            "Test Accuracy of   V24: 100% ( 1/ 1)\n",
            "Test Accuracy of   V28: 100% ( 8/ 8)\n",
            "Test Accuracy of   V30: 100% ( 2/ 2)\n",
            "Test Accuracy of   V31: 100% (27/27)\n",
            "Test Accuracy of    V4: 100% ( 3/ 3)\n",
            "Test Accuracy of    V6:  0% ( 0/ 1)\n",
            "Test Accuracy of    V7: 100% ( 1/ 1)\n",
            "Test Accuracy of   W11: 100% ( 1/ 1)\n",
            "Test Accuracy of   W18: 100% ( 2/ 2)\n",
            "Test Accuracy of   W19: 100% ( 1/ 1)\n",
            "Test Accuracy of   W22:  0% ( 0/ 1)\n",
            "Test Accuracy of   W24: 75% ( 6/ 8)\n",
            "Test Accuracy of   W25: 100% ( 3/ 3)\n",
            "Test Accuracy of    X1: 100% (47/47)\n",
            "Test Accuracy of    X8: 50% ( 1/ 2)\n",
            "Test Accuracy of    Y2: 100% ( 2/ 2)\n",
            "Test Accuracy of    Y3: 100% ( 1/ 1)\n",
            "Test Accuracy of    Y5: 100% ( 2/ 2)\n",
            "Test Accuracy of    Z1: 100% (10/10)\n",
            "Test Accuracy of   Z11: 100% ( 3/ 3)\n",
            "Test Accuracy of    Z7: 100% ( 1/ 1)\n",
            "\n",
            "Accuracy: 93.318%\n",
            "\n",
            "Precision: 92.420%\n",
            "\n",
            "Recall: 93.318%\n",
            "\n",
            "F1-score: 92.582%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    }
  ]
}