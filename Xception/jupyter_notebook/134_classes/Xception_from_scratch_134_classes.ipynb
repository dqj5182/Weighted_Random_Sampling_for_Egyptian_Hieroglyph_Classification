{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Egyptian_model_with_Xception_from_scratch_134_classes.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Po0ZVacIYsP0",
        "outputId": "88922701-5186-4e82-f204-543a8e086f4e"
      },
      "source": [
        "!pip install timm"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting timm\n",
            "  Downloading timm-0.4.12-py3-none-any.whl (376 kB)\n",
            "\u001b[?25l\r\u001b[K     |▉                               | 10 kB 17.9 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 20 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 30 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 40 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 51 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 61 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |██████                          | 71 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |███████                         | 81 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 92 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 102 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 112 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 122 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 133 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 143 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 153 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 163 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 174 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 184 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 194 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 204 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 215 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 225 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 235 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 245 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 256 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 266 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 276 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 286 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 296 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 307 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 317 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 327 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 337 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 348 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 358 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 368 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 376 kB 6.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from timm) (1.10.0+cu111)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm) (0.11.1+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->timm) (3.10.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (1.19.5)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (7.1.2)\n",
            "Installing collected packages: timm\n",
            "Successfully installed timm-0.4.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8iEiGSblxJzW"
      },
      "source": [
        "import os, os.path\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from pathlib import Path\n",
        "from torchvision import datasets, models, transforms\n",
        "import timm\n",
        "\n",
        "# check if CUDA is available\n",
        "train_on_gpu = torch.cuda.is_available()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jd6KU8VMz6J3"
      },
      "source": [
        "Module: Load_data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lWX0BW_w_kC"
      },
      "source": [
        "def load_data(hieroglyph_directory_path, batch_size=20, num_workers=0):\n",
        "    train_dir = os.path.join(hieroglyph_directory_path, 'train/')\n",
        "    test_dir = os.path.join(hieroglyph_directory_path, 'test/')\n",
        "\n",
        "    classes = []\n",
        "\n",
        "    for filename in os.listdir(train_dir):\n",
        "        if filename == '.DS_Store':\n",
        "            pass\n",
        "        else:\n",
        "            classes.append(filename)\n",
        "\n",
        "    classes.sort()\n",
        "\n",
        "    # print(\"Our classes:\", classes)\n",
        "    # print(len(classes))\n",
        "\n",
        "    data_transform_train = transforms.Compose([transforms.ToTensor(),\n",
        "                                                  transforms.Resize((75, 75)),\n",
        "                                                  transforms.Normalize((0.5,), (0.5,))]) \n",
        "\n",
        "    data_transform_test = transforms.Compose([transforms.ToTensor(),\n",
        "                                                  transforms.RandomApply([transforms.RandomHorizontalFlip()]),\n",
        "                                                  transforms.RandomRotation(degrees=(-10, 10)),\n",
        "                                                  transforms.RandomAffine(degrees=0, translate=(.1, .1)),\n",
        "                                                  transforms.RandomApply([transforms.ColorJitter(brightness=(1, 1.2),\n",
        "                                                                                                  contrast=(1, 1.5),\n",
        "                                                                                                  saturation=(1, 1.5),\n",
        "                                                                                                  hue=(0, 0.5))]),\n",
        "                                                  transforms.RandomErasing(p=0.5, scale=(0.05, 0.05), ratio=(0.3, 3.3), value=0,\n",
        "                                                                            inplace=False),\n",
        "                                                  transforms.Resize((75, 75)),\n",
        "                                                  transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "    train_data = datasets.ImageFolder(train_dir, transform=data_transform_train)\n",
        "    test_data = datasets.ImageFolder(test_dir, transform=data_transform_test)\n",
        "\n",
        "    # print('Num training images: ', len(train_data))\n",
        "    # print('Num test images: ', len(test_data))\n",
        "\n",
        "    # prepare data loaders\n",
        "    train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
        "                                               num_workers=num_workers, shuffle=True)\n",
        "    test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size,\n",
        "                                              num_workers=num_workers, shuffle=True)\n",
        "\n",
        "    return train_loader, test_loader, classes"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4sXUrPPz7iF"
      },
      "source": [
        "Module: Train_model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2N_rnKLxN5c"
      },
      "source": [
        "def train_model(train_loader, optimizer, conv_net_model, criterion, my_lr_scheduler, n_epochs):\n",
        "    # track training loss over time\n",
        "    losses = []\n",
        "    \n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "\n",
        "        # keep track of training and validation loss\n",
        "        train_loss = 0.0\n",
        "\n",
        "        # model by default is set to train\n",
        "        for batch_i, (data, target) in enumerate(train_loader):\n",
        "            # move tensors to GPU if CUDA is available\n",
        "            if train_on_gpu:\n",
        "                data, target = data.cuda(), target.cuda()\n",
        "            # clear the gradients of all optimized variables\n",
        "            optimizer.zero_grad()\n",
        "            # forward pass: compute predicted outputs by passing inputs to the model\n",
        "            output = conv_net_model(data)\n",
        "            # calculate the batch loss\n",
        "            loss = criterion(output, target)\n",
        "            # backward pass: compute gradient of the loss with respect to model parameters\n",
        "            loss.backward()\n",
        "            # perform a single optimization step (parameter update)\n",
        "            optimizer.step()\n",
        "            # update training loss\n",
        "            train_loss += loss.item()\n",
        "\n",
        "            my_lr_scheduler.step()\n",
        "\n",
        "            if batch_i % 20 == 19:  # print training loss every specified number of mini-batches\n",
        "                print('Epoch %d, Batch %d loss: %.16f' %\n",
        "                    (epoch, batch_i + 1, train_loss / 20))\n",
        "                losses.append(train_loss / 20)\n",
        "                train_loss = 0.0\n",
        "\n",
        "    return conv_net_model, losses"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Rrxo5RDz96U"
      },
      "source": [
        "Module: Test_model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ay-HlMJnxU9v"
      },
      "source": [
        "def test_model(classes, conv_net_model, test_loader, criterion):\n",
        "    # track test loss\n",
        "    test_loss = 0.0\n",
        "    class_correct = list(0. for i in range(len(classes)))\n",
        "    class_total = list(0. for i in range(len(classes)))\n",
        "\n",
        "    conv_net_model.eval()  # eval mode\n",
        "\n",
        "    labels = []\n",
        "    predictions = []\n",
        "    # iterate over test data\n",
        "    for data, target in test_loader:\n",
        "        # move tensors to GPU if CUDA is available\n",
        "        if train_on_gpu:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        # forward pass: compute predicted outputs by passing inputs to the model\n",
        "        output = conv_net_model(data)\n",
        "\n",
        "        # calculate the batch loss\n",
        "        loss = criterion(output, target)\n",
        "        # update  test loss\n",
        "        test_loss += loss.item() * data.size(0)\n",
        "        # convert output probabilities to predicted class\n",
        "        _, pred = torch.max(output, 1)\n",
        "        # compare predictions to true label\n",
        "        correct_tensor = pred.eq(target.data.view_as(pred))\n",
        "        correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
        "        # calculate test accuracy for each object class\n",
        "        for i in range(len(target.data)):\n",
        "            label = target.data[i]\n",
        "            class_correct[label] += correct[i].item()\n",
        "            class_total[label] += 1\n",
        "        \n",
        "        # Will be used for calculating Recall, Precision, and F1-score\n",
        "        labels.extend(target.data.view_as(pred).tolist())\n",
        "        predictions.extend(pred.tolist())\n",
        "\n",
        "\n",
        "    # calculate avg test loss\n",
        "    test_loss = test_loss / len(test_loader.dataset)\n",
        "    print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
        "\n",
        "    return test_loss, class_correct, class_total, labels, predictions"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHh3PXE80Asa"
      },
      "source": [
        "Check whether CUDA is available (Change runtime type if not)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9TYPQH7x4zw",
        "outputId": "e72c8fe9-b4e4-4ebb-fb0d-12bb43400ab0"
      },
      "source": [
        "if not train_on_gpu:\n",
        "    print('CUDA is not available.  Training on CPU ...')\n",
        "else:\n",
        "    print('CUDA is available!  Training on GPU ...')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA is available!  Training on GPU ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lYw8EKVx8Q7"
      },
      "source": [
        "Load Hieroglyph Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "laLvoRy1yewl",
        "outputId": "442e7830-f2f1-4ad7-dcc9-b70f58bd0f75"
      },
      "source": [
        "# Connecting and Mounting to the Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odaoZt9GyfUt"
      },
      "source": [
        "data_dir = '/content/drive/MyDrive/EgyptianHieroglyphDataset_134/'"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dF22MAnmyiC1",
        "outputId": "5136bdd7-e8f8-4f0d-92f3-fcac3eb3aa06"
      },
      "source": [
        "hieroglyph_for_train = []\n",
        "file_count_list = []\n",
        "\n",
        "for name in os.listdir('/content/drive/MyDrive/EgyptianHieroglyphDataset_134/train/'):\n",
        "  path, dirs, files = next(os.walk(\"/content/drive/MyDrive/EgyptianHieroglyphDataset_134/train/\"+name))\n",
        "  file_count = len(files)\n",
        "  print(name, file_count)\n",
        "  file_count_list.append(file_count)\n",
        "  hieroglyph_for_train.append(name)\n",
        "\n",
        "hieroglyph_dict = dict(zip(hieroglyph_for_train, file_count_list))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aa15 2\n",
            "Aa26 4\n",
            "Aa27 2\n",
            "Z1 39\n",
            "Z11 8\n",
            "Z7 3\n",
            "Y2 5\n",
            "Y3 2\n",
            "Y5 6\n",
            "E34 97\n",
            "E1 5\n",
            "E23 8\n",
            "E9 8\n",
            "W18 5\n",
            "W24 31\n",
            "W11 4\n",
            "W22 1\n",
            "W19 3\n",
            "W25 9\n",
            "D21 146\n",
            "D4 29\n",
            "D46 40\n",
            "D1 4\n",
            "D36 47\n",
            "D58 28\n",
            "D2 19\n",
            "D35 45\n",
            "D60 4\n",
            "D28 13\n",
            "D10 2\n",
            "D39 1\n",
            "D56 2\n",
            "D19 2\n",
            "D52 4\n",
            "D54 9\n",
            "D156 2\n",
            "X1 185\n",
            "X8 4\n",
            "U15 10\n",
            "U28 2\n",
            "U1 20\n",
            "U33 13\n",
            "U7 3\n",
            "T28 1\n",
            "T22 7\n",
            "T21 2\n",
            "T20 3\n",
            "T30 2\n",
            "V31 106\n",
            "V28 28\n",
            "V13 63\n",
            "V4 10\n",
            "V30 6\n",
            "V7 4\n",
            "V24 4\n",
            "V6 1\n",
            "R8 53\n",
            "R4 2\n",
            "Q3 61\n",
            "Q1 13\n",
            "Q7 2\n",
            "P8 12\n",
            "P6 2\n",
            "P98 4\n",
            "P1 4\n",
            "S29 212\n",
            "S34 8\n",
            "S24 1\n",
            "S28 1\n",
            "O50 84\n",
            "O49 10\n",
            "O28 8\n",
            "O34 15\n",
            "O1 16\n",
            "O31 5\n",
            "O4 11\n",
            "I9 116\n",
            "I10 32\n",
            "G17 156\n",
            "L1 2\n",
            "M17 291\n",
            "M44 5\n",
            "M42 4\n",
            "M1 2\n",
            "M12 2\n",
            "M18 10\n",
            "M195 2\n",
            "M20 2\n",
            "M23 30\n",
            "M41 2\n",
            "M3 3\n",
            "M16 1\n",
            "M8 1\n",
            "M40 2\n",
            "M29 2\n",
            "H6 5\n",
            "N35 358\n",
            "N5 16\n",
            "N1 14\n",
            "N37 24\n",
            "N14 11\n",
            "N31 13\n",
            "N17 6\n",
            "N29 14\n",
            "N18 15\n",
            "N41 2\n",
            "N30 9\n",
            "N25 1\n",
            "N36 1\n",
            "F13 6\n",
            "F16 5\n",
            "F35 2\n",
            "F34 8\n",
            "F31 6\n",
            "F4 3\n",
            "F40 1\n",
            "F18 4\n",
            "F9 2\n",
            "F26 3\n",
            "G39 16\n",
            "G43 157\n",
            "G5 24\n",
            "G40 6\n",
            "G7 8\n",
            "G35 30\n",
            "G1 28\n",
            "G21 1\n",
            "G25 21\n",
            "G36 7\n",
            "G4 6\n",
            "G14 1\n",
            "G26 1\n",
            "G29 2\n",
            "G37 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XeQQ7PjZzKd9"
      },
      "source": [
        "Number of images for each hieroglyph "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        },
        "id": "W6IzWR2RyjxM",
        "outputId": "f9c50743-7bed-4b76-c11b-b7b0ff245835"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame({\"Hieroglyph\":hieroglyph_for_train, \"Count\":file_count_list})\n",
        "\n",
        "df_sorted= df.sort_values('Count',ascending=False)\n",
        "\n",
        "plt.figure(figsize=(20,10))\n",
        "# make bar plot with matplotlib\n",
        "plt.bar('Hieroglyph', 'Count',data=df_sorted)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 134 artists>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3oOm8rSx7tp"
      },
      "source": [
        "# Number of images processed in a single training\n",
        "batch_size = 20\n",
        "num_workers = 0\n",
        "\n",
        "# The load_data function is from hieroglyph_data_preparation python file\n",
        "train_loader, test_loader, classes = load_data(data_dir)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJm8sGiBx_q5"
      },
      "source": [
        "ResNet Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkLXVJGkxemC"
      },
      "source": [
        "# Whether to extract features with the model\n",
        "feature_extract = False\n",
        "# Other selections\n",
        "loss_function = \"cross-entropy\"\n",
        "model_selection = \"xception\"\n",
        "optim_selection = \"Adam\"\n",
        "\n",
        "# False if you want scratch model, True if you want pretrained model\n",
        "whether_to_pretrain = False\n",
        "\n",
        "# Load the model\n",
        "if model_selection == \"resnet-50\":\n",
        "    resnet50 = models.resnet50(pretrained=whether_to_pretrain)\n",
        "    # Number of features in the last layer of resnet\n",
        "    n_inputs = resnet50.fc.in_features\n",
        "    # Add last linear layer (n_inputs -> 40 hieroglyph classes)\n",
        "    last_layer = nn.Sequential(\n",
        "                    nn.Linear(n_inputs, len(classes)))\n",
        "    resnet50.fc = last_layer\n",
        "    if train_on_gpu:\n",
        "      resnet50.cuda()\n",
        "    # Specify optimizer (Adam) and learning rate = 0.001\n",
        "    if optim_selection == \"Adam\":\n",
        "        optimizer = optim.Adam(resnet50.parameters(), lr=0.001)\n",
        "\n",
        "elif model_selection == \"inception-v3\":\n",
        "    inception_v3 = models.inception_v3(pretrained=whether_to_pretrain)\n",
        "    # Number of features in the last layer of resnet\n",
        "    n_inputs = inception_v3.fc.in_features\n",
        "    # Add last linear layer (n_inputs -> 40 hieroglyph classes)\n",
        "    last_layer = nn.Sequential(\n",
        "                    nn.Linear(n_inputs, len(classes)))\n",
        "    inception_v3.fc = last_layer\n",
        "    if train_on_gpu:\n",
        "      inception_v3.cuda()\n",
        "    # Specify optimizer (Adam) and learning rate = 0.001\n",
        "    if optim_selection == \"Adam\":\n",
        "        optimizer = optim.Adam(inception_v3.parameters(), lr=0.001)\n",
        "\n",
        "elif model_selection == \"xception\":\n",
        "    xception = timm.create_model('xception', pretrained=whether_to_pretrain)\n",
        "    # Number of features in the last layer of resnet\n",
        "    n_inputs = xception.fc.in_features\n",
        "    # Add last linear layer (n_inputs -> 40 hieroglyph classes)\n",
        "    last_layer = nn.Sequential(\n",
        "                    nn.Linear(n_inputs, len(classes)))\n",
        "    xception.fc = last_layer\n",
        "    if train_on_gpu:\n",
        "      xception.cuda()\n",
        "    # Specify optimizer (Adam) and learning rate = 0.001\n",
        "    if optim_selection == \"Adam\":\n",
        "        optimizer = optim.Adam(xception.parameters(), lr=0.001)\n",
        "\n",
        "# Specify loss function (categorical cross-entropy)\n",
        "if loss_function == \"cross-entropy\":\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Exponential Decay to strengthen learning\n",
        "decayRate = 0.999\n",
        "my_lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=decayRate)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2vnErB1yHmM"
      },
      "source": [
        "Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOB03noWyEvQ",
        "outputId": "c8207207-248e-4033-eddb-51fcd64cb459"
      },
      "source": [
        "# number of epochs to train the model\n",
        "n_epochs = 50\n",
        "\n",
        "if model_selection == \"resnet-50\":\n",
        "  # The train_model function is from model_training python file\n",
        "  resnet50, train_losses = train_model(train_loader, optimizer, resnet50, criterion, my_lr_scheduler, n_epochs)\n",
        "elif model_selection == \"inception-v3\":\n",
        "  # The train_model function is from model_training python file\n",
        "  inception_v3, train_losses = train_model(train_loader, optimizer, inception_v3, criterion, my_lr_scheduler, n_epochs)\n",
        "elif model_selection == \"xception\":\n",
        "  # The train_model function is from model_training python file\n",
        "  xception, train_losses = train_model(train_loader, optimizer, xception, criterion, my_lr_scheduler, n_epochs)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Batch 20 loss: 3.9132046103477478\n",
            "Epoch 1, Batch 40 loss: 2.6858452856540680\n",
            "Epoch 1, Batch 60 loss: 2.5765818953514099\n",
            "Epoch 1, Batch 80 loss: 2.0386566340923311\n",
            "Epoch 1, Batch 100 loss: 1.6746618509292603\n",
            "Epoch 1, Batch 120 loss: 1.6441741883754730\n",
            "Epoch 1, Batch 140 loss: 1.3562736272811891\n",
            "Epoch 2, Batch 20 loss: 1.0359419181942939\n",
            "Epoch 2, Batch 40 loss: 1.0996276021003724\n",
            "Epoch 2, Batch 60 loss: 0.9956145882606506\n",
            "Epoch 2, Batch 80 loss: 0.9330944553017616\n",
            "Epoch 2, Batch 100 loss: 1.2041504055261611\n",
            "Epoch 2, Batch 120 loss: 1.0979652076959610\n",
            "Epoch 2, Batch 140 loss: 0.8024886883795261\n",
            "Epoch 3, Batch 20 loss: 0.6480690985918045\n",
            "Epoch 3, Batch 40 loss: 0.6839598335325718\n",
            "Epoch 3, Batch 60 loss: 0.6990409553050995\n",
            "Epoch 3, Batch 80 loss: 0.6191357754170894\n",
            "Epoch 3, Batch 100 loss: 0.6659661296755075\n",
            "Epoch 3, Batch 120 loss: 0.4853781923651695\n",
            "Epoch 3, Batch 140 loss: 0.5426253559067845\n",
            "Epoch 4, Batch 20 loss: 0.4832719258964062\n",
            "Epoch 4, Batch 40 loss: 0.4210759863257408\n",
            "Epoch 4, Batch 60 loss: 0.4143560692667961\n",
            "Epoch 4, Batch 80 loss: 0.3806099969893694\n",
            "Epoch 4, Batch 100 loss: 0.3889629550278187\n",
            "Epoch 4, Batch 120 loss: 0.3528394905850291\n",
            "Epoch 4, Batch 140 loss: 0.4587908383458853\n",
            "Epoch 5, Batch 20 loss: 0.3272710192948580\n",
            "Epoch 5, Batch 40 loss: 0.3030460603535176\n",
            "Epoch 5, Batch 60 loss: 0.2786627050489187\n",
            "Epoch 5, Batch 80 loss: 0.2001952027902007\n",
            "Epoch 5, Batch 100 loss: 0.2399754278361797\n",
            "Epoch 5, Batch 120 loss: 0.2686761725926772\n",
            "Epoch 5, Batch 140 loss: 0.2746766702271998\n",
            "Epoch 6, Batch 20 loss: 0.1924282027408481\n",
            "Epoch 6, Batch 40 loss: 0.2350738797336817\n",
            "Epoch 6, Batch 60 loss: 0.1773178798146546\n",
            "Epoch 6, Batch 80 loss: 0.1959547922015190\n",
            "Epoch 6, Batch 100 loss: 0.1872733997181058\n",
            "Epoch 6, Batch 120 loss: 0.1603588602505624\n",
            "Epoch 6, Batch 140 loss: 0.2004278455860913\n",
            "Epoch 7, Batch 20 loss: 0.1361880016047508\n",
            "Epoch 7, Batch 40 loss: 0.1037271007662639\n",
            "Epoch 7, Batch 60 loss: 0.1255593619309366\n",
            "Epoch 7, Batch 80 loss: 0.1174393062479794\n",
            "Epoch 7, Batch 100 loss: 0.1135444279294461\n",
            "Epoch 7, Batch 120 loss: 0.0908568217419088\n",
            "Epoch 7, Batch 140 loss: 0.1221687196986750\n",
            "Epoch 8, Batch 20 loss: 0.0915077480487525\n",
            "Epoch 8, Batch 40 loss: 0.1001175533747301\n",
            "Epoch 8, Batch 60 loss: 0.0419424322783016\n",
            "Epoch 8, Batch 80 loss: 0.0812261002138257\n",
            "Epoch 8, Batch 100 loss: 0.0669783073943108\n",
            "Epoch 8, Batch 120 loss: 0.0468818590044975\n",
            "Epoch 8, Batch 140 loss: 0.0609474508790299\n",
            "Epoch 9, Batch 20 loss: 0.0671868800884113\n",
            "Epoch 9, Batch 40 loss: 0.0353942807530984\n",
            "Epoch 9, Batch 60 loss: 0.0349963442422450\n",
            "Epoch 9, Batch 80 loss: 0.0381140786688775\n",
            "Epoch 9, Batch 100 loss: 0.0309105577878654\n",
            "Epoch 9, Batch 120 loss: 0.0402640188694932\n",
            "Epoch 9, Batch 140 loss: 0.0300827165599912\n",
            "Epoch 10, Batch 20 loss: 0.0113393914361950\n",
            "Epoch 10, Batch 40 loss: 0.0445982014294714\n",
            "Epoch 10, Batch 60 loss: 0.0186282891081646\n",
            "Epoch 10, Batch 80 loss: 0.0253619455732405\n",
            "Epoch 10, Batch 100 loss: 0.0149235223478172\n",
            "Epoch 10, Batch 120 loss: 0.0144131698529236\n",
            "Epoch 10, Batch 140 loss: 0.0261477279826067\n",
            "Epoch 11, Batch 20 loss: 0.0233928192406893\n",
            "Epoch 11, Batch 40 loss: 0.0110816992935725\n",
            "Epoch 11, Batch 60 loss: 0.0100329686014447\n",
            "Epoch 11, Batch 80 loss: 0.0073672565049492\n",
            "Epoch 11, Batch 100 loss: 0.0112108578905463\n",
            "Epoch 11, Batch 120 loss: 0.0103683065332007\n",
            "Epoch 11, Batch 140 loss: 0.0073022031225264\n",
            "Epoch 12, Batch 20 loss: 0.0040381764440099\n",
            "Epoch 12, Batch 40 loss: 0.0057580011140089\n",
            "Epoch 12, Batch 60 loss: 0.0061853170045651\n",
            "Epoch 12, Batch 80 loss: 0.0060386154451407\n",
            "Epoch 12, Batch 100 loss: 0.0051414595043752\n",
            "Epoch 12, Batch 120 loss: 0.0042642614047509\n",
            "Epoch 12, Batch 140 loss: 0.0070987254672218\n",
            "Epoch 13, Batch 20 loss: 0.0038057993981056\n",
            "Epoch 13, Batch 40 loss: 0.0045303346298169\n",
            "Epoch 13, Batch 60 loss: 0.0053899984632153\n",
            "Epoch 13, Batch 80 loss: 0.0045859337784350\n",
            "Epoch 13, Batch 100 loss: 0.0043775887286756\n",
            "Epoch 13, Batch 120 loss: 0.0035681153720361\n",
            "Epoch 13, Batch 140 loss: 0.0037198772479314\n",
            "Epoch 14, Batch 20 loss: 0.0042531676270301\n",
            "Epoch 14, Batch 40 loss: 0.0046895302337362\n",
            "Epoch 14, Batch 60 loss: 0.0037424647773150\n",
            "Epoch 14, Batch 80 loss: 0.0045806277135853\n",
            "Epoch 14, Batch 100 loss: 0.0029975741897943\n",
            "Epoch 14, Batch 120 loss: 0.0029638115200214\n",
            "Epoch 14, Batch 140 loss: 0.0041684276133310\n",
            "Epoch 15, Batch 20 loss: 0.0030061567638768\n",
            "Epoch 15, Batch 40 loss: 0.0028287826979067\n",
            "Epoch 15, Batch 60 loss: 0.0026742749396362\n",
            "Epoch 15, Batch 80 loss: 0.0025328374176752\n",
            "Epoch 15, Batch 100 loss: 0.0034549729898572\n",
            "Epoch 15, Batch 120 loss: 0.0026155553496210\n",
            "Epoch 15, Batch 140 loss: 0.0028883332503028\n",
            "Epoch 16, Batch 20 loss: 0.0033661996771116\n",
            "Epoch 16, Batch 40 loss: 0.0024186780152377\n",
            "Epoch 16, Batch 60 loss: 0.0029112264630385\n",
            "Epoch 16, Batch 80 loss: 0.0025030537566636\n",
            "Epoch 16, Batch 100 loss: 0.0042521115537966\n",
            "Epoch 16, Batch 120 loss: 0.0034294775075978\n",
            "Epoch 16, Batch 140 loss: 0.0019243443210144\n",
            "Epoch 17, Batch 20 loss: 0.0021540623769397\n",
            "Epoch 17, Batch 40 loss: 0.0030413017608225\n",
            "Epoch 17, Batch 60 loss: 0.0024534697440686\n",
            "Epoch 17, Batch 80 loss: 0.0032968352927128\n",
            "Epoch 17, Batch 100 loss: 0.0021313103847206\n",
            "Epoch 17, Batch 120 loss: 0.0032120784191648\n",
            "Epoch 17, Batch 140 loss: 0.0019748882332351\n",
            "Epoch 18, Batch 20 loss: 0.0022889645246323\n",
            "Epoch 18, Batch 40 loss: 0.0019937648263294\n",
            "Epoch 18, Batch 60 loss: 0.0019803256058367\n",
            "Epoch 18, Batch 80 loss: 0.0017836190148955\n",
            "Epoch 18, Batch 100 loss: 0.0021223927498795\n",
            "Epoch 18, Batch 120 loss: 0.0021064885106171\n",
            "Epoch 18, Batch 140 loss: 0.0019426753118751\n",
            "Epoch 19, Batch 20 loss: 0.0024169367534341\n",
            "Epoch 19, Batch 40 loss: 0.0014849237340968\n",
            "Epoch 19, Batch 60 loss: 0.0024134251769283\n",
            "Epoch 19, Batch 80 loss: 0.0019564391463064\n",
            "Epoch 19, Batch 100 loss: 0.0026876950636506\n",
            "Epoch 19, Batch 120 loss: 0.0020984673748899\n",
            "Epoch 19, Batch 140 loss: 0.0024123260736815\n",
            "Epoch 20, Batch 20 loss: 0.0019907019275706\n",
            "Epoch 20, Batch 40 loss: 0.0012324627779890\n",
            "Epoch 20, Batch 60 loss: 0.0023360839521047\n",
            "Epoch 20, Batch 80 loss: 0.0011700277202181\n",
            "Epoch 20, Batch 100 loss: 0.0012980384315597\n",
            "Epoch 20, Batch 120 loss: 0.0021174903129577\n",
            "Epoch 20, Batch 140 loss: 0.0017447234771680\n",
            "Epoch 21, Batch 20 loss: 0.0050457050892874\n",
            "Epoch 21, Batch 40 loss: 0.0018808498600265\n",
            "Epoch 21, Batch 60 loss: 0.0028181669011246\n",
            "Epoch 21, Batch 80 loss: 0.0014746297150850\n",
            "Epoch 21, Batch 100 loss: 0.0024088408972602\n",
            "Epoch 21, Batch 120 loss: 0.0019991725974251\n",
            "Epoch 21, Batch 140 loss: 0.0015568794158753\n",
            "Epoch 22, Batch 20 loss: 0.0018539877055446\n",
            "Epoch 22, Batch 40 loss: 0.0026408911682665\n",
            "Epoch 22, Batch 60 loss: 0.0012802991521312\n",
            "Epoch 22, Batch 80 loss: 0.0023468947765650\n",
            "Epoch 22, Batch 100 loss: 0.0012776941191987\n",
            "Epoch 22, Batch 120 loss: 0.0017279919324210\n",
            "Epoch 22, Batch 140 loss: 0.0018158374834456\n",
            "Epoch 23, Batch 20 loss: 0.0017257304090890\n",
            "Epoch 23, Batch 40 loss: 0.0015149765647948\n",
            "Epoch 23, Batch 60 loss: 0.0017529571669002\n",
            "Epoch 23, Batch 80 loss: 0.0017429140469176\n",
            "Epoch 23, Batch 100 loss: 0.0016924307827139\n",
            "Epoch 23, Batch 120 loss: 0.0021784976182971\n",
            "Epoch 23, Batch 140 loss: 0.0012920220833621\n",
            "Epoch 24, Batch 20 loss: 0.0019569525291445\n",
            "Epoch 24, Batch 40 loss: 0.0024537627352402\n",
            "Epoch 24, Batch 60 loss: 0.0015282322652638\n",
            "Epoch 24, Batch 80 loss: 0.0013322563492693\n",
            "Epoch 24, Batch 100 loss: 0.0021035384415882\n",
            "Epoch 24, Batch 120 loss: 0.0017396077630110\n",
            "Epoch 24, Batch 140 loss: 0.0013707370053453\n",
            "Epoch 25, Batch 20 loss: 0.0018135825266654\n",
            "Epoch 25, Batch 40 loss: 0.0015396497212350\n",
            "Epoch 25, Batch 60 loss: 0.0016876120062079\n",
            "Epoch 25, Batch 80 loss: 0.0014874742948450\n",
            "Epoch 25, Batch 100 loss: 0.0019751290645218\n",
            "Epoch 25, Batch 120 loss: 0.0019671388407005\n",
            "Epoch 25, Batch 140 loss: 0.0018589893472381\n",
            "Epoch 26, Batch 20 loss: 0.0013405555306235\n",
            "Epoch 26, Batch 40 loss: 0.0012366925868264\n",
            "Epoch 26, Batch 60 loss: 0.0012205416715005\n",
            "Epoch 26, Batch 80 loss: 0.0015477690787520\n",
            "Epoch 26, Batch 100 loss: 0.0015741990238894\n",
            "Epoch 26, Batch 120 loss: 0.0013100729702273\n",
            "Epoch 26, Batch 140 loss: 0.0018629844271345\n",
            "Epoch 27, Batch 20 loss: 0.0010394633369287\n",
            "Epoch 27, Batch 40 loss: 0.0016195703457925\n",
            "Epoch 27, Batch 60 loss: 0.0015993398003047\n",
            "Epoch 27, Batch 80 loss: 0.0018367384560406\n",
            "Epoch 27, Batch 100 loss: 0.0014575456167222\n",
            "Epoch 27, Batch 120 loss: 0.0011547113565030\n",
            "Epoch 27, Batch 140 loss: 0.0015837207422010\n",
            "Epoch 28, Batch 20 loss: 0.0012333680060692\n",
            "Epoch 28, Batch 40 loss: 0.0016344275078154\n",
            "Epoch 28, Batch 60 loss: 0.0018079835019307\n",
            "Epoch 28, Batch 80 loss: 0.0011322631296935\n",
            "Epoch 28, Batch 100 loss: 0.0014039507426787\n",
            "Epoch 28, Batch 120 loss: 0.0017393862377503\n",
            "Epoch 28, Batch 140 loss: 0.0010534580134845\n",
            "Epoch 29, Batch 20 loss: 0.0017963677761145\n",
            "Epoch 29, Batch 40 loss: 0.0013034420335316\n",
            "Epoch 29, Batch 60 loss: 0.0010933476296486\n",
            "Epoch 29, Batch 80 loss: 0.0014072649486479\n",
            "Epoch 29, Batch 100 loss: 0.0018923934010672\n",
            "Epoch 29, Batch 120 loss: 0.0012753250208334\n",
            "Epoch 29, Batch 140 loss: 0.0019900892788428\n",
            "Epoch 30, Batch 20 loss: 0.0014579115042579\n",
            "Epoch 30, Batch 40 loss: 0.0022871142675285\n",
            "Epoch 30, Batch 60 loss: 0.0011979088201770\n",
            "Epoch 30, Batch 80 loss: 0.0015465165182832\n",
            "Epoch 30, Batch 100 loss: 0.0009258544028853\n",
            "Epoch 30, Batch 120 loss: 0.0010832662897883\n",
            "Epoch 30, Batch 140 loss: 0.0010337045561755\n",
            "Epoch 31, Batch 20 loss: 0.0013503617388778\n",
            "Epoch 31, Batch 40 loss: 0.0012839753486332\n",
            "Epoch 31, Batch 60 loss: 0.0014305894248537\n",
            "Epoch 31, Batch 80 loss: 0.0012631456396775\n",
            "Epoch 31, Batch 100 loss: 0.0018458737889887\n",
            "Epoch 31, Batch 120 loss: 0.0012152688781498\n",
            "Epoch 31, Batch 140 loss: 0.0013530094875023\n",
            "Epoch 32, Batch 20 loss: 0.0010692751064198\n",
            "Epoch 32, Batch 40 loss: 0.0019991326706077\n",
            "Epoch 32, Batch 60 loss: 0.0014317490480607\n",
            "Epoch 32, Batch 80 loss: 0.0016480382415466\n",
            "Epoch 32, Batch 100 loss: 0.0018917972978670\n",
            "Epoch 32, Batch 120 loss: 0.0011005350053892\n",
            "Epoch 32, Batch 140 loss: 0.0010339616099373\n",
            "Epoch 33, Batch 20 loss: 0.0011959023264353\n",
            "Epoch 33, Batch 40 loss: 0.0013838796381606\n",
            "Epoch 33, Batch 60 loss: 0.0014796921517700\n",
            "Epoch 33, Batch 80 loss: 0.0010759090771899\n",
            "Epoch 33, Batch 100 loss: 0.0012722969870083\n",
            "Epoch 33, Batch 120 loss: 0.0015744309494039\n",
            "Epoch 33, Batch 140 loss: 0.0014575636218069\n",
            "Epoch 34, Batch 20 loss: 0.0037948358774884\n",
            "Epoch 34, Batch 40 loss: 0.0016582693468081\n",
            "Epoch 34, Batch 60 loss: 0.0011332876543747\n",
            "Epoch 34, Batch 80 loss: 0.0010730304536992\n",
            "Epoch 34, Batch 100 loss: 0.0012138189180405\n",
            "Epoch 34, Batch 120 loss: 0.0009749994147569\n",
            "Epoch 34, Batch 140 loss: 0.0010547803474765\n",
            "Epoch 35, Batch 20 loss: 0.0012974299141206\n",
            "Epoch 35, Batch 40 loss: 0.0009666925347119\n",
            "Epoch 35, Batch 60 loss: 0.0012016576562019\n",
            "Epoch 35, Batch 80 loss: 0.0018219487363240\n",
            "Epoch 35, Batch 100 loss: 0.0011022105085431\n",
            "Epoch 35, Batch 120 loss: 0.0012662906214246\n",
            "Epoch 35, Batch 140 loss: 0.0010747864929726\n",
            "Epoch 36, Batch 20 loss: 0.0011930677472265\n",
            "Epoch 36, Batch 40 loss: 0.0014082216934185\n",
            "Epoch 36, Batch 60 loss: 0.0010902882568189\n",
            "Epoch 36, Batch 80 loss: 0.0011266714100202\n",
            "Epoch 36, Batch 100 loss: 0.0013750906422501\n",
            "Epoch 36, Batch 120 loss: 0.0014304619297036\n",
            "Epoch 36, Batch 140 loss: 0.0010643400499248\n",
            "Epoch 37, Batch 20 loss: 0.0009436178806936\n",
            "Epoch 37, Batch 40 loss: 0.0012124418775784\n",
            "Epoch 37, Batch 60 loss: 0.0010349273303291\n",
            "Epoch 37, Batch 80 loss: 0.0018432453580317\n",
            "Epoch 37, Batch 100 loss: 0.0009322377642093\n",
            "Epoch 37, Batch 120 loss: 0.0013288712594658\n",
            "Epoch 37, Batch 140 loss: 0.0012076676750439\n",
            "Epoch 38, Batch 20 loss: 0.0017375370225636\n",
            "Epoch 38, Batch 40 loss: 0.0011345821316354\n",
            "Epoch 38, Batch 60 loss: 0.0008998329096357\n",
            "Epoch 38, Batch 80 loss: 0.0012868910736870\n",
            "Epoch 38, Batch 100 loss: 0.0019211855076719\n",
            "Epoch 38, Batch 120 loss: 0.0011861653008964\n",
            "Epoch 38, Batch 140 loss: 0.0009985447075451\n",
            "Epoch 39, Batch 20 loss: 0.0016467463501613\n",
            "Epoch 39, Batch 40 loss: 0.0022758424223866\n",
            "Epoch 39, Batch 60 loss: 0.0010587213153485\n",
            "Epoch 39, Batch 80 loss: 0.0009729155543027\n",
            "Epoch 39, Batch 100 loss: 0.0011037237112760\n",
            "Epoch 39, Batch 120 loss: 0.0008781149415881\n",
            "Epoch 39, Batch 140 loss: 0.0014104998510447\n",
            "Epoch 40, Batch 20 loss: 0.0012479910452385\n",
            "Epoch 40, Batch 40 loss: 0.0009755330262124\n",
            "Epoch 40, Batch 60 loss: 0.0011712770705344\n",
            "Epoch 40, Batch 80 loss: 0.0012603912531631\n",
            "Epoch 40, Batch 100 loss: 0.0011404072822188\n",
            "Epoch 40, Batch 120 loss: 0.0010925951006357\n",
            "Epoch 40, Batch 140 loss: 0.0013648970729264\n",
            "Epoch 41, Batch 20 loss: 0.0015208424549201\n",
            "Epoch 41, Batch 40 loss: 0.0009502936525678\n",
            "Epoch 41, Batch 60 loss: 0.0014485579551547\n",
            "Epoch 41, Batch 80 loss: 0.0011878259734658\n",
            "Epoch 41, Batch 100 loss: 0.0016477153272717\n",
            "Epoch 41, Batch 120 loss: 0.0011450760233856\n",
            "Epoch 41, Batch 140 loss: 0.0012877191489679\n",
            "Epoch 42, Batch 20 loss: 0.0010530666128034\n",
            "Epoch 42, Batch 40 loss: 0.0007626630962477\n",
            "Epoch 42, Batch 60 loss: 0.0013742479961365\n",
            "Epoch 42, Batch 80 loss: 0.0012084226385923\n",
            "Epoch 42, Batch 100 loss: 0.0015057360025821\n",
            "Epoch 42, Batch 120 loss: 0.0011284530482953\n",
            "Epoch 42, Batch 140 loss: 0.0011884175662999\n",
            "Epoch 43, Batch 20 loss: 0.0012062915717252\n",
            "Epoch 43, Batch 40 loss: 0.0009893969050609\n",
            "Epoch 43, Batch 60 loss: 0.0012352140227449\n",
            "Epoch 43, Batch 80 loss: 0.0021402694212156\n",
            "Epoch 43, Batch 100 loss: 0.0019255862673162\n",
            "Epoch 43, Batch 120 loss: 0.0011018219214748\n",
            "Epoch 43, Batch 140 loss: 0.0011977252128418\n",
            "Epoch 44, Batch 20 loss: 0.0010243143988191\n",
            "Epoch 44, Batch 40 loss: 0.0025482973142061\n",
            "Epoch 44, Batch 60 loss: 0.0008000571353477\n",
            "Epoch 44, Batch 80 loss: 0.0011683333483234\n",
            "Epoch 44, Batch 100 loss: 0.0012792943016393\n",
            "Epoch 44, Batch 120 loss: 0.0014474484065431\n",
            "Epoch 44, Batch 140 loss: 0.0009562345891027\n",
            "Epoch 45, Batch 20 loss: 0.0017225366580533\n",
            "Epoch 45, Batch 40 loss: 0.0013278869715577\n",
            "Epoch 45, Batch 60 loss: 0.0009374332279549\n",
            "Epoch 45, Batch 80 loss: 0.0008781071250269\n",
            "Epoch 45, Batch 100 loss: 0.0010982480584062\n",
            "Epoch 45, Batch 120 loss: 0.0012692219708697\n",
            "Epoch 45, Batch 140 loss: 0.0009985280994442\n",
            "Epoch 46, Batch 20 loss: 0.0013875084201572\n",
            "Epoch 46, Batch 40 loss: 0.0015059300145367\n",
            "Epoch 46, Batch 60 loss: 0.0021483149721462\n",
            "Epoch 46, Batch 80 loss: 0.0011261658975855\n",
            "Epoch 46, Batch 100 loss: 0.0017027246780344\n",
            "Epoch 46, Batch 120 loss: 0.0007670792241697\n",
            "Epoch 46, Batch 140 loss: 0.0016664250157191\n",
            "Epoch 47, Batch 20 loss: 0.0012127707843320\n",
            "Epoch 47, Batch 40 loss: 0.0017531350153149\n",
            "Epoch 47, Batch 60 loss: 0.0013094096764689\n",
            "Epoch 47, Batch 80 loss: 0.0022753829951398\n",
            "Epoch 47, Batch 100 loss: 0.0011953918976360\n",
            "Epoch 47, Batch 120 loss: 0.0009350174819701\n",
            "Epoch 47, Batch 140 loss: 0.0009677015303168\n",
            "Epoch 48, Batch 20 loss: 0.0012976847283426\n",
            "Epoch 48, Batch 40 loss: 0.0015423886019562\n",
            "Epoch 48, Batch 60 loss: 0.0011664011311950\n",
            "Epoch 48, Batch 80 loss: 0.0015146446399740\n",
            "Epoch 48, Batch 100 loss: 0.0013122236232448\n",
            "Epoch 48, Batch 120 loss: 0.0012843505523051\n",
            "Epoch 48, Batch 140 loss: 0.0012449485999241\n",
            "Epoch 49, Batch 20 loss: 0.0011934624220885\n",
            "Epoch 49, Batch 40 loss: 0.0012571277533425\n",
            "Epoch 49, Batch 60 loss: 0.0013800535889459\n",
            "Epoch 49, Batch 80 loss: 0.0010354221813031\n",
            "Epoch 49, Batch 100 loss: 0.0018142137065297\n",
            "Epoch 49, Batch 120 loss: 0.0011374597015674\n",
            "Epoch 49, Batch 140 loss: 0.0013149150778190\n",
            "Epoch 50, Batch 20 loss: 0.0011641501172562\n",
            "Epoch 50, Batch 40 loss: 0.0012797252158634\n",
            "Epoch 50, Batch 60 loss: 0.0014183293227688\n",
            "Epoch 50, Batch 80 loss: 0.0013018681231188\n",
            "Epoch 50, Batch 100 loss: 0.0014305035510915\n",
            "Epoch 50, Batch 120 loss: 0.0011400953881093\n",
            "Epoch 50, Batch 140 loss: 0.0011713095518644\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfA7ZjLR1BZP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "4a61d25f-a8b5-4fc2-ba5d-cf283846a9b4"
      },
      "source": [
        "plt.plot(train_losses)\n",
        "plt.title(\"Training Loss\")\n",
        "plt.show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ItLyF9dQyJFL"
      },
      "source": [
        "Testing the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGki98W3SoEW"
      },
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNavYOynyE6d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f66fc8c-dc2c-4789-9150-b667830b9d18"
      },
      "source": [
        "# The test_model function is from model_testing python file\n",
        "test_loss, class_correct, class_total, labels, predictions = test_model(classes, xception, test_loader, criterion)\n",
        "\n",
        "# Test accuracy for each hieroglyph\n",
        "for i in range(len(classes)):\n",
        "    if class_total[i] > 0:\n",
        "        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (classes[i], 100 * class_correct[i] / class_total[i], np.sum(class_correct[i]), np.sum(class_total[i])))\n",
        "    else:\n",
        "        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
        "\n",
        "# Total Test accuracy\n",
        "print(\"\\nAccuracy: {:.3%}\".format(accuracy_score(labels, predictions)))\n",
        "print(\"\\nPrecision: {:.3%}\".format(precision_score(labels, predictions, average = 'weighted')))\n",
        "print(\"\\nRecall: {:.3%}\".format(recall_score(labels, predictions, average = 'weighted')))\n",
        "print(\"\\nF1-score: {:.3%}\".format(f1_score(labels, predictions, average = 'weighted')))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 7.131799\n",
            "\n",
            "Test Accuracy of  Aa15:  0% ( 0/ 1)\n",
            "Test Accuracy of  Aa26:  0% ( 0/ 1)\n",
            "Test Accuracy of  Aa27:  0% ( 0/ 1)\n",
            "Test Accuracy of    D1:  0% ( 0/ 1)\n",
            "Test Accuracy of   D10:  0% ( 0/ 1)\n",
            "Test Accuracy of  D156:  0% ( 0/ 1)\n",
            "Test Accuracy of   D19:  0% ( 0/ 1)\n",
            "Test Accuracy of    D2:  0% ( 0/ 5)\n",
            "Test Accuracy of   D21: 10% ( 4/37)\n",
            "Test Accuracy of   D28: 25% ( 1/ 4)\n",
            "Test Accuracy of   D35: 25% ( 3/12)\n",
            "Test Accuracy of   D36:  8% ( 1/12)\n",
            "Test Accuracy of   D39:  0% ( 0/ 1)\n",
            "Test Accuracy of    D4:  0% ( 0/ 8)\n",
            "Test Accuracy of   D46: 10% ( 1/10)\n",
            "Test Accuracy of   D52:  0% ( 0/ 1)\n",
            "Test Accuracy of   D54: 33% ( 1/ 3)\n",
            "Test Accuracy of   D56:  0% ( 0/ 1)\n",
            "Test Accuracy of   D58: 12% ( 1/ 8)\n",
            "Test Accuracy of   D60: 50% ( 1/ 2)\n",
            "Test Accuracy of    E1: 50% ( 1/ 2)\n",
            "Test Accuracy of   E23:  0% ( 0/ 2)\n",
            "Test Accuracy of   E34:  8% ( 2/25)\n",
            "Test Accuracy of    E9:  0% ( 0/ 2)\n",
            "Test Accuracy of   F13:  0% ( 0/ 2)\n",
            "Test Accuracy of   F16:  0% ( 0/ 2)\n",
            "Test Accuracy of   F18:  0% ( 0/ 2)\n",
            "Test Accuracy of   F26:  0% ( 0/ 1)\n",
            "Test Accuracy of   F31:  0% ( 0/ 2)\n",
            "Test Accuracy of   F34:  0% ( 0/ 2)\n",
            "Test Accuracy of   F35:  0% ( 0/ 1)\n",
            "Test Accuracy of    F4:  0% ( 0/ 1)\n",
            "Test Accuracy of   F40:  0% ( 0/ 1)\n",
            "Test Accuracy of    F9:  0% ( 0/ 1)\n",
            "Test Accuracy of    G1: 28% ( 2/ 7)\n",
            "Test Accuracy of   G14:  0% ( 0/ 1)\n",
            "Test Accuracy of   G17:  5% ( 2/39)\n",
            "Test Accuracy of   G21:  0% ( 0/ 1)\n",
            "Test Accuracy of   G25:  0% ( 0/ 6)\n",
            "Test Accuracy of   G26:  0% ( 0/ 1)\n",
            "Test Accuracy of   G29:  0% ( 0/ 1)\n",
            "Test Accuracy of   G35: 12% ( 1/ 8)\n",
            "Test Accuracy of   G36:  0% ( 0/ 2)\n",
            "Test Accuracy of   G37:  0% ( 0/ 1)\n",
            "Test Accuracy of   G39: 20% ( 1/ 5)\n",
            "Test Accuracy of    G4:  0% ( 0/ 2)\n",
            "Test Accuracy of   G40:  0% ( 0/ 2)\n",
            "Test Accuracy of   G43: 32% (13/40)\n",
            "Test Accuracy of    G5: 28% ( 2/ 7)\n",
            "Test Accuracy of    G7: 66% ( 2/ 3)\n",
            "Test Accuracy of    H6:  0% ( 0/ 2)\n",
            "Test Accuracy of   I10: 11% ( 1/ 9)\n",
            "Test Accuracy of    I9: 10% ( 3/30)\n",
            "Test Accuracy of    L1:  0% ( 0/ 1)\n",
            "Test Accuracy of    M1:  0% ( 0/ 1)\n",
            "Test Accuracy of   M12:  0% ( 0/ 1)\n",
            "Test Accuracy of   M16:  0% ( 0/ 1)\n",
            "Test Accuracy of   M17: 23% (17/73)\n",
            "Test Accuracy of   M18:  0% ( 0/ 3)\n",
            "Test Accuracy of  M195:  0% ( 0/ 1)\n",
            "Test Accuracy of   M20:  0% ( 0/ 1)\n",
            "Test Accuracy of   M23: 50% ( 4/ 8)\n",
            "Test Accuracy of   M29:  0% ( 0/ 1)\n",
            "Test Accuracy of    M3:  0% ( 0/ 1)\n",
            "Test Accuracy of   M40:  0% ( 0/ 1)\n",
            "Test Accuracy of   M41:  0% ( 0/ 1)\n",
            "Test Accuracy of   M42:  0% ( 0/ 1)\n",
            "Test Accuracy of   M44:  0% ( 0/ 2)\n",
            "Test Accuracy of    M8:  0% ( 0/ 1)\n",
            "Test Accuracy of    N1: 25% ( 1/ 4)\n",
            "Test Accuracy of   N14: 100% ( 3/ 3)\n",
            "Test Accuracy of   N17:  0% ( 0/ 2)\n",
            "Test Accuracy of   N18:  0% ( 0/ 4)\n",
            "Test Accuracy of   N25:  0% ( 0/ 1)\n",
            "Test Accuracy of   N29:  0% ( 0/ 4)\n",
            "Test Accuracy of   N30:  0% ( 0/ 3)\n",
            "Test Accuracy of   N31:  0% ( 0/ 4)\n",
            "Test Accuracy of   N35: 42% (38/90)\n",
            "Test Accuracy of   N36:  0% ( 0/ 1)\n",
            "Test Accuracy of   N37: 16% ( 1/ 6)\n",
            "Test Accuracy of   N41:  0% ( 0/ 1)\n",
            "Test Accuracy of    N5: 20% ( 1/ 5)\n",
            "Test Accuracy of    O1:  0% ( 0/ 4)\n",
            "Test Accuracy of   O28:  0% ( 0/ 2)\n",
            "Test Accuracy of   O31:  0% ( 0/ 2)\n",
            "Test Accuracy of   O34:  0% ( 0/ 4)\n",
            "Test Accuracy of    O4: 66% ( 2/ 3)\n",
            "Test Accuracy of   O49: 33% ( 1/ 3)\n",
            "Test Accuracy of   O50:  4% ( 1/22)\n",
            "Test Accuracy of    P1:  0% ( 0/ 1)\n",
            "Test Accuracy of    P6:  0% ( 0/ 1)\n",
            "Test Accuracy of    P8:  0% ( 0/ 4)\n",
            "Test Accuracy of   P98:  0% ( 0/ 1)\n",
            "Test Accuracy of    Q1: 50% ( 2/ 4)\n",
            "Test Accuracy of    Q3: 12% ( 2/16)\n",
            "Test Accuracy of    Q7:  0% ( 0/ 1)\n",
            "Test Accuracy of    R4:  0% ( 0/ 1)\n",
            "Test Accuracy of    R8:  7% ( 1/14)\n",
            "Test Accuracy of   S24:  0% ( 0/ 1)\n",
            "Test Accuracy of   S28:  0% ( 0/ 1)\n",
            "Test Accuracy of   S29: 30% (16/53)\n",
            "Test Accuracy of   S34: 50% ( 1/ 2)\n",
            "Test Accuracy of   T20:  0% ( 0/ 1)\n",
            "Test Accuracy of   T21:  0% ( 0/ 1)\n",
            "Test Accuracy of   T22: 50% ( 1/ 2)\n",
            "Test Accuracy of   T28:  0% ( 0/ 1)\n",
            "Test Accuracy of   T30:  0% ( 0/ 1)\n",
            "Test Accuracy of    U1: 20% ( 1/ 5)\n",
            "Test Accuracy of   U15: 33% ( 1/ 3)\n",
            "Test Accuracy of   U28:  0% ( 0/ 1)\n",
            "Test Accuracy of   U33:  0% ( 0/ 4)\n",
            "Test Accuracy of    U7:  0% ( 0/ 1)\n",
            "Test Accuracy of   V13: 18% ( 3/16)\n",
            "Test Accuracy of   V24:  0% ( 0/ 1)\n",
            "Test Accuracy of   V28: 50% ( 4/ 8)\n",
            "Test Accuracy of   V30:  0% ( 0/ 2)\n",
            "Test Accuracy of   V31: 14% ( 4/27)\n",
            "Test Accuracy of    V4: 33% ( 1/ 3)\n",
            "Test Accuracy of    V6:  0% ( 0/ 1)\n",
            "Test Accuracy of    V7:  0% ( 0/ 1)\n",
            "Test Accuracy of   W11:  0% ( 0/ 1)\n",
            "Test Accuracy of   W18:  0% ( 0/ 2)\n",
            "Test Accuracy of   W19:  0% ( 0/ 1)\n",
            "Test Accuracy of   W22:  0% ( 0/ 1)\n",
            "Test Accuracy of   W24:  0% ( 0/ 8)\n",
            "Test Accuracy of   W25:  0% ( 0/ 3)\n",
            "Test Accuracy of    X1: 10% ( 5/47)\n",
            "Test Accuracy of    X8:  0% ( 0/ 2)\n",
            "Test Accuracy of    Y2:  0% ( 0/ 2)\n",
            "Test Accuracy of    Y3:  0% ( 0/ 1)\n",
            "Test Accuracy of    Y5:  0% ( 0/ 2)\n",
            "Test Accuracy of    Z1: 30% ( 3/10)\n",
            "Test Accuracy of   Z11: 100% ( 3/ 3)\n",
            "Test Accuracy of    Z7:  0% ( 0/ 1)\n",
            "\n",
            "Accuracy: 18.757%\n",
            "\n",
            "Precision: 62.046%\n",
            "\n",
            "Recall: 18.757%\n",
            "\n",
            "F1-score: 25.045%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    }
  ]
}
